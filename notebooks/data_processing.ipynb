{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im skipping leap days currently in multiple places\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70128\n",
      "61368\n",
      "8760\n"
     ]
    }
   ],
   "source": [
    "months = {1: \"jan\", 2: \"feb\", 3: \"mar\", 4: \"apr\", 5: \"may\", 6: \"jun\", 7: \"jul\", 8: \"aug\", 9: \"sep\", 10: \"oct\", 11: \"nov\", 12: \"dec\"}\n",
    "\n",
    "startdate = datetime.datetime(year=2010, month=1, day=1, hour=0, minute=0, second=0)\n",
    "curr = startdate\n",
    "enddate = datetime.datetime(year=2018, month=1, day=1, hour=0, minute=0, second=0)\n",
    "\n",
    "allhours = []\n",
    "\n",
    "while curr < enddate:\n",
    "    allhours.append(curr)\n",
    "    curr += datetime.timedelta(hours=1)\n",
    "    \n",
    "trainhours = allhours[0:-8760] #all but last year, not a leap year\n",
    "testhours = allhours[-8760:]\n",
    "print(len(allhours))\n",
    "print(len(trainhours))\n",
    "print(len(testhours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ERCOT data\n",
    "subregions = ['COAST', 'EAST', 'FAR_WEST', 'NORTH', 'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST', 'ERCOT']\n",
    "other_subregions = ['COAST', 'EAST', 'FWEST', 'NORTH', 'NCENT', 'SOUTH', 'SCENT', 'WEST', 'ERCOT']\n",
    "\n",
    "\n",
    "lds = datetime.datetime(year=2016, month=2, day=29, hour=0, minute=0) #lines 1415 to 1439\n",
    "lde = datetime.datetime(year=2016, month=2, day=29, hour=23, minute=0)\n",
    "\n",
    "path = \"/home/chase/projects/peakload/data/ercot/\"\n",
    "ercot2017 = pd.read_excel(path + \"native_Load_2017.xlsx\") #different subregions Index(['Hour Ending', 'COAST', 'EAST', 'FWEST', 'NORTH', 'NCENT', 'SOUTH', 'SCENT', 'WEST', 'ERCOT'],dtype='object')\n",
    "ercot2016 = pd.read_excel(path + \"native_Load_2016.xlsx\") #leap year\n",
    "#ercot2016.drop(ercot2016.index[1415:1439], inplace=True)\n",
    "\n",
    "ercot2015 = pd.read_excel(path + \"native_Load_2015.xls\")\n",
    "ercot2014 = pd.read_excel(path + \"2014_ERCOT_Hourly_Load_Data.xls\")\n",
    "ercot2013 = pd.read_excel(path + \"2013_ERCOT_Hourly_Load_Data.xls\")\n",
    "ercot2012 = pd.read_excel(path + \"2012_ERCOT_Hourly_Load_Data.xls\") #leap year\n",
    "#ercot2012.drop(ercot2012.index[1415:1439], inplace=True)\n",
    "\n",
    "ercot2011 = pd.read_excel(path + \"2011_ERCOT_Hourly_Load_Data.xls\")\n",
    "ercot2010 = pd.read_excel(path + \"2010_ERCOT_Hourly_Load_Data.xls\")\n",
    "\n",
    "#ercotdata = list(ercot2010['ERCOT']) + list(ercot2011['ERCOT']) + list(ercot2012['ERCOT']) + list(ercot2013['ERCOT']) + list(ercot2014['ERCOT']) + list(ercot2015['ERCOT']) + list(ercot2016['ERCOT']) + list(ercot2017['ERCOT'])\n",
    "yearly_data = {}\n",
    "yearly_data['ERCOT'] = [list(ercot2010['ERCOT']), list(ercot2011['ERCOT']), list(ercot2012['ERCOT']), list(ercot2013['ERCOT']), list(ercot2014['ERCOT']), list(ercot2015['ERCOT']), list(ercot2016['ERCOT']), list(ercot2017['ERCOT'])]\n",
    "\n",
    "for region in subregions:\n",
    "    yearly_data[region] = [list(ercot2010[region]), list(ercot2011[region]), list(ercot2012[region]), list(ercot2013[region]), list(ercot2014[region]), list(ercot2015[region]), list(ercot2016[region])]\n",
    "\n",
    "for region in other_subregions:\n",
    "    r = subregions[other_subregions.index(region)]\n",
    "    yearly_data[r].append(list(ercot2017[region]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for subregions\n",
    "vectorized_subregions = {}\n",
    "for region in subregions:\n",
    "    vectorized_subregions[region] = {}\n",
    "    train_data_vec = np.array(yearly_data[region][0]) - np.mean(yearly_data[region][0])\n",
    "    means = [np.mean(yearly_data[region][0])]\n",
    "    for i in range(1, len(yearly_data[region])-1):\n",
    "        yr = yearly_data[region][i]\n",
    "        m = np.nanmean(yr)\n",
    "        means.append(m)\n",
    "        train_data_vec = np.concatenate((train_data_vec, np.array(yr)-m), axis=0)\n",
    "        \n",
    "    vectorized_subregions[region]['train_data'] = train_data_vec    \n",
    "    vectorized_subregions[region]['means'] = means\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for region in subregions:\n",
    "    #if switching back to monthly labels output feature engineered data elsewhere\n",
    "    #train_data_vec = vectorized_subregions[region]['train_data']\n",
    "    \n",
    "    train_data_vals = []\n",
    "    #train_data_labels = []\n",
    "    train_data_labels = np.array([])\n",
    "    #m = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(trainhours)):\n",
    "        if trainhours[i].month - 1 == m and i != len(trainhours) - 1:\n",
    "            train_data_vals.append(train_data_vec[i,])\n",
    "        elif i == len(trainhours) - 1:\n",
    "            train_data_vals.append(train_data_vec[i,])\n",
    "            for val in train_data_vals:\n",
    "                greater = np.sum([1 for k in train_data_vals if k >= val])/float(len(train_data_vals))\n",
    "                train_data_labels.append(1.0 - greater)\n",
    "        else:\n",
    "            for val in train_data_vals:\n",
    "                greater = np.sum([1 for k in train_data_vals if k >= val])/float(len(train_data_vals))\n",
    "                train_data_labels.append(1.0 - greater)\n",
    "\n",
    "            train_data_vals = []\n",
    "            train_data_vals.append(train_data_vec[i,]) #start with missed value\n",
    "            m = (m + 1) % 12\n",
    "    vectorized_subregions[region]['train_labels'] = np.array(train_data_labels)\n",
    "            \n",
    "    \"\"\"\n",
    "    for i in range(len(yearly_data[region])-1):\n",
    "        year_data = yearly_data[region][i]\n",
    "        train_data_l = np.zeros((len(year_data),))\n",
    "        for j in range(len(year_data)):\n",
    "            greater = np.sum([1 for k in year_data if k >= year_data[j]])/float(len(year_data))\n",
    "            train_data_l[j] = 1.0 - greater\n",
    "        train_data_labels = np.concatenate((train_data_labels, train_data_l), axis=0)\n",
    "            \n",
    "    vectorized_subregions[region]['train_labels'] = train_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f213ef73ba8>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f213ef3b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 0 #not neccessarily a true month so load value normalization is off in plot\n",
    "b = 8760\n",
    "plt.plot(vectorized_subregions[region]['train_labels'][a:b])\n",
    "plt.plot( (vectorized_subregions[region]['train_data'][a:b,]  - np.min(vectorized_subregions[region]['train_data'][a:b,]))/ (np.max(vectorized_subregions[region]['train_data'][a:b,]) - np.min(vectorized_subregions[region]['train_data'][a:b,])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.21956698167793 10330.675211917747\n",
      "1.1445290359099922 1389.0497308542554\n",
      "157.5580701856505 1235.861525615093\n",
      "-6.286314908476045 862.2773959771353\n",
      "55.294436102682454 12689.296038363827\n",
      "74.74464079097235 2906.584283652104\n",
      "69.80779480723267 6095.32943668585\n",
      "14.267152541100186 1046.8526042098674\n",
      "568.7498755367494 36555.92622727587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "#use system-wide loadgrowth for all regions for mean shifting\n",
    "for region in vectorized_subregions:\n",
    "    A = np.vstack((np.array([0, 1, 2, 3, 4, 5, 6]), np.array([1, 1, 1, 1, 1, 1, 1]))).T\n",
    "    a, b = np.linalg.lstsq(A, np.array(vectorized_subregions[region]['means']))[0]\n",
    "    print(a, b)\n",
    "    projected_mean = a*7.0 + b\n",
    "    vectorized_subregions[region]['projected_mean'] = projected_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for region in vectorized_subregions:\n",
    "    test_data_vec = np.array(yearly_data[region][-1]) - vectorized_subregions[region]['projected_mean']\n",
    "    vectorized_subregions[region]['test_data'] = test_data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor region in vectorized_subregions:\\n    test_data_vec = vectorized_subregions[region]['test_data']\\n    \\n    test_data_vals = []\\n    test_data_labels = []\\n    m = 0\\n    \\n    for i in range(len(testhours)):\\n        if testhours[i].month - 1 == m and i != len(testhours) - 1:\\n            test_data_vals.append(test_data_vec[i,])\\n        elif i == len(testhours) - 1:\\n            test_data_vals.append(test_data_vec[i,])\\n            for val in test_data_vals:\\n                greater = np.sum([1 for k in test_data_vals if k >= val])/float(len(test_data_vals))\\n                test_data_labels.append(1.0 - greater)\\n        else:\\n            for val in test_data_vals:\\n                greater = np.sum([ 1 for k in test_data_vals if k >= val ])/float(len(test_data_vals))\\n                test_data_labels.append(1.0 - greater)\\n                \\n            test_data_vals = []\\n            test_data_vals.append(test_data_vec[i,])\\n            m = (m + 1) % 12\\n    vectorized_subregions[region]['test_labels'] = np.array(test_data_labels)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for region in subregions:\n",
    "    \n",
    "    #train_data_vec = vectorized_subregions[region]['train_data']\n",
    "    \n",
    "    test_data_vals = []\n",
    "    #train_data_labels = []\n",
    "    #m = 0\n",
    "    \n",
    "    year_data = yearly_data[region][-1]\n",
    "    test_data_l = np.zeros((len(year_data),))\n",
    "    for j in range(len(year_data)):\n",
    "        greater = np.sum([1 for k in year_data if k >= year_data[j]])/float(len(year_data))\n",
    "        test_data_l[j] = 1.0 - greater\n",
    "            \n",
    "    vectorized_subregions[region]['test_labels'] = test_data_l\n",
    "\n",
    "\"\"\"\n",
    "for region in vectorized_subregions:\n",
    "    test_data_vec = vectorized_subregions[region]['test_data']\n",
    "    \n",
    "    test_data_vals = []\n",
    "    test_data_labels = []\n",
    "    m = 0\n",
    "    \n",
    "    for i in range(len(testhours)):\n",
    "        if testhours[i].month - 1 == m and i != len(testhours) - 1:\n",
    "            test_data_vals.append(test_data_vec[i,])\n",
    "        elif i == len(testhours) - 1:\n",
    "            test_data_vals.append(test_data_vec[i,])\n",
    "            for val in test_data_vals:\n",
    "                greater = np.sum([1 for k in test_data_vals if k >= val])/float(len(test_data_vals))\n",
    "                test_data_labels.append(1.0 - greater)\n",
    "        else:\n",
    "            for val in test_data_vals:\n",
    "                greater = np.sum([ 1 for k in test_data_vals if k >= val ])/float(len(test_data_vals))\n",
    "                test_data_labels.append(1.0 - greater)\n",
    "                \n",
    "            test_data_vals = []\n",
    "            test_data_vals.append(test_data_vec[i,])\n",
    "            m = (m + 1) % 12\n",
    "    vectorized_subregions[region]['test_labels'] = np.array(test_data_labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n",
      "(61368,) (8760,) (61368,) (8760,)\n"
     ]
    }
   ],
   "source": [
    "for region in vectorized_subregions:\n",
    "    print(vectorized_subregions[region]['train_data'].shape, vectorized_subregions[region]['test_data'].shape, vectorized_subregions[region]['train_labels'].shape, vectorized_subregions[region]['test_labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize load values\n",
    "for region in vectorized_subregions:\n",
    "    train_max = np.nanmax(vectorized_subregions[region]['train_data'])\n",
    "    train_min = np.nanmin(vectorized_subregions[region]['train_data'])\n",
    "    \n",
    "    vectorized_subregions[region]['train_data_norm'] = (vectorized_subregions[region]['train_data'] - train_min)/(train_max - train_min)\n",
    "    vectorized_subregions[region]['test_data_norm'] = (vectorized_subregions[region]['train_data'] - train_min)/(train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def itermean(oldmean, newval, num):\n",
    "    if np.isnan(newval):\n",
    "        out = oldmean\n",
    "    elif np.isnan(oldmean) and not np.isnan(newval):\n",
    "        out = newval\n",
    "    else:\n",
    "        out = oldmean + ((newval - oldmean)/float(num))\n",
    "    return(out)\n",
    "\n",
    "def itervar(oldvar, oldmean, newval, num):\n",
    "    if np.isnan(newval):\n",
    "        out = oldvar\n",
    "    else:\n",
    "        n = float(num)\n",
    "        out = ((n - 1)*oldvar + (newval - oldmean)*(newval - oldmean))/n\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70128,)\n",
      "70128\n",
      "8760\n",
      "61368\n"
     ]
    }
   ],
   "source": [
    "all_loads = np.concatenate((vectorized_subregions['ERCOT']['train_data'], vectorized_subregions['ERCOT']['test_data']))\n",
    "print(all_loads.shape)\n",
    "print(len(allhours))\n",
    "print(len(testhours))\n",
    "print(len(trainhours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_matching():\n",
    "    out = {}\n",
    "    for h in range(24):\n",
    "        out[h] = [np.nan]\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAR_WEST', 'NORTH', 'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorized_subregions.keys())[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERCOT', 'COAST', 'EAST', 'FAR_WEST', 'NORTH', 'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n"
     ]
    }
   ],
   "source": [
    "reorg_regions = ['ERCOT'] + list(vectorized_subregions.keys())[:-1] #['ERCOT'] + list(vectorized_subregions.keys())[4:-1] #ercot and east are done\n",
    "print(reorg_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERCOT\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:84: RuntimeWarning: All-NaN axis encountered\n",
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:89: RuntimeWarning: All-NaN axis encountered\n",
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:90: RuntimeWarning: All-NaN axis encountered\n",
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:91: RuntimeWarning: Mean of empty slice\n",
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:92: RuntimeWarning: Degrees of freedom <= 0 for slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 0, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 1, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 2, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 3, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 4, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 5, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 6, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 7, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 8, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 9, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 10, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 11, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 12, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 13, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 14, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 15, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 16, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 17, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 18, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 19, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 20, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 21, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 22, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n",
      "datetime.datetime(2009, 12, 31, 23, 0) is not in list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:780: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:781: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "COAST\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "EAST\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "FAR_WEST\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "NORTH\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "NORTH_C\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "SOUTHERN\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "SOUTH_C\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "WEST\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "#do this for 'ERCOT' only\n",
    "\n",
    "seasons = {1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2, 10: 3, 11: 3, 12: 3}\n",
    "\n",
    "for region in reorg_regions:\n",
    "    load_features = {}\n",
    "    print(region)\n",
    "    all_loads = np.concatenate((vectorized_subregions[region]['train_data_norm'], vectorized_subregions[region]['test_data_norm']))\n",
    "    \n",
    "    maxsofar = all_loads[0,]\n",
    "    meansofar = all_loads[0,]\n",
    "    varsofar = 0.0\n",
    "    count = 0\n",
    "    year = 2010\n",
    "    month = 1\n",
    "    \n",
    "    for i in range(len(allhours)):\n",
    "        load_features[str(allhours[i])] = {}\n",
    "        currtime = allhours[i]\n",
    "        curr_year = currtime.year\n",
    "        #curr_month = currtime.month\n",
    "\n",
    "        if curr_year > year:\n",
    "            print(curr_year)\n",
    "            year = curr_year\n",
    "            maxsofar = all_loads[i,]\n",
    "            meansofar = all_loads[i,]\n",
    "            varsofar = 0.0\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            if all_loads[i] > maxsofar:\n",
    "                maxsofar = all_loads[i]\n",
    "            varsofar = itervar(varsofar, meansofar, all_loads[i], count)\n",
    "            meansofar = itermean(meansofar, all_loads[i], count)\n",
    "            \n",
    "        \"\"\"\n",
    "        elif curr_month == 1 and month == 12:\n",
    "            print(curr_month, currtime.year)\n",
    "            month = curr_month\n",
    "            maxsofar = all_loads[i,]\n",
    "            meansofar = all_loads[i,]\n",
    "            varsofar = 0.0\n",
    "            count = 0\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        dt_back = currtime\n",
    "        dayback = 28\n",
    "        stop_1 = currtime - datetime.timedelta(days=dayback)\n",
    "        #stop_2 = currtime - datetime.timedelta(days=30*2)\n",
    "\n",
    "        #the while loop is horrible\n",
    "        if region == \"ERCOT\":\n",
    "            try:\n",
    "                h = currtime.hour\n",
    "                for t in range(24):\n",
    "                    mhour = [ all_loads[allhours.index((currtime - datetime.timedelta(hours=t)) - datetime.timedelta(hours=24*i))] for i in range(dayback) ]\n",
    "                    load_features[str(currtime)][\"hourmax_\" + str((h-t)%24)] = np.nanmax(mhour)\n",
    "                    load_features[str(currtime)][\"hourmin_\" + str((h-t)%24)] = np.nanmin(mhour)\n",
    "                    load_features[str(currtime)][\"hourmean_\" + str((h-t)%24)] = np.nanmean(mhour)\n",
    "                    load_features[str(currtime)][\"hourvar_\" + str((h-t)%24)] = np.nanvar(mhour)\n",
    "                    hhist = np.histogram(mhour, bins=7, range=(np.nanmin(mhour), np.nanmax(mhour)))[0]\n",
    "                    load_features[str(currtime)][\"hourhist_\" + str((h-t)%24)] = list((1.0/sum(hhist)) * hhist)\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                matching_hour = init_matching()\n",
    "                while dt_back > stop_1:\n",
    "                    if dt_back < allhours[0]:\n",
    "                        break\n",
    "                    else:\n",
    "                        matching_hour[dt_back.hour].append(all_loads[allhours.index(dt_back)])\n",
    "                    dt_back -= datetime.timedelta(hours=1)\n",
    "\n",
    "                for hour in range(24):\n",
    "                    if len(matching_hour[hour]) == 0:\n",
    "                        load_features[str(currtime)][\"hourhist_\" + str(hour)] = list(np.nan * np.zeros((7,)))\n",
    "                        load_features[str(currtime)][\"hourmax_\" + str(hour)] = np.nan\n",
    "                        load_features[str(currtime)][\"hourmin_\" + str(hour)] = np.nan\n",
    "                        load_features[str(currtime)][\"hourmean_\" + str(hour)] = np.nan\n",
    "                        load_features[str(currtime)][\"hourvar_\" + str(hour)] = np.nan\n",
    "                    else:\n",
    "                        try:\n",
    "                            hhist = np.histogram(matching_hour[hour], bins=7, range=(np.nanmin(matching_hour[hour], np.nanmax(matching_hour[hour]))))[0]\n",
    "                            hhist = (1.0/sum(hhist)) * hhist\n",
    "                        except Exception as err:\n",
    "                            hhist = np.nan * np.zeros((7,))\n",
    "                        load_features[str(currtime)][\"hourhist_\" + str(hour)] = list(hhist)\n",
    "                        load_features[str(currtime)][\"hourmax_\" + str(hour)] = np.nanmax(matching_hour[hour])\n",
    "                        load_features[str(currtime)][\"hourmin_\" + str(hour)] = np.nanmin(matching_hour[hour])\n",
    "                        load_features[str(currtime)][\"hourmean_\" + str(hour)] = np.nanmean(matching_hour[hour])\n",
    "                        load_features[str(currtime)][\"hourvar_\" + str(hour)] = np.nanvar(matching_hour[hour])\n",
    "        \"\"\"\n",
    "        #dhhist = np.histogram(loads_dayhour, bins=7, range=(np.nanmin(loads_dayhour), np.nanmax(loads_dayhour)))[0]\n",
    "        #dayhourhist = (1.0/sum(dhhist)) * dhhist\n",
    "        #hhist = np.histogram(loads_hour, bins=7, range=(np.nanmin(loads_hour), np.nanmax(loads_hour)))[0]\n",
    "        #hourhist = (1.0/sum(hhist)) * hhist\n",
    "\n",
    "        #load_features[currtime][\"dayhourmax\"] = dayhourmax #1\n",
    "        #load_features[currtime][\"dayhourmin\"] = dayhourmin #1\n",
    "        #load_features[currtime][\"dayhourhist\"] = dayhourhist #7\n",
    "        #load_features[currtime][\"dayhourmean\"] = dayhourmean #1\n",
    "        #load_features[currtime][\"dayhourvar\"] = dayhourvar #1\n",
    "        #load_features[currtime][\"hourmax\"] = hourmax #1\n",
    "        #load_features[currtime][\"hourmin\"] = hourmin #1\n",
    "        #load_features[currtime][\"hourhist\"] = hourhist #7\n",
    "        #load_features[currtime][\"hourmean\"] = hourmean #1\n",
    "        #load_features[currtime][\"hourvar\"] = hourvar #1\n",
    "        \"\"\"\n",
    "        load_features[str(currtime)][\"load\"] = all_loads[allhours.index(currtime)]\n",
    "        load_features[str(currtime)][\"maxloadsofar\"] = maxsofar #1\n",
    "        load_features[str(currtime)][\"meanloadsofar\"] = meansofar #1\n",
    "        load_features[str(currtime)][\"varsofar\"] = varsofar #1\n",
    "        load_features[str(currtime)][\"hour\"] = float(currtime.hour)/23.0\n",
    "        load_features[str(currtime)][\"month\"] = float(currtime.month - 1.0)/11.0 #1\n",
    "        load_features[str(currtime)][\"week\"] = float(currtime.isocalendar()[1])/52.0 #1\n",
    "        load_features[str(currtime)][\"weekday\"] = float(currtime.weekday())/6.0 #1\n",
    "        load_features[str(currtime)][\"season\"] = float(seasons[currtime.month])/3.0 #1\n",
    "        \n",
    "        \n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/\" + region + \"_load_features.json\", 'w') as d:\n",
    "        out = json.dumps(load_features)\n",
    "        d.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hour': 0.6956521739130435,\n",
       " 'load': 0.5772493052300539,\n",
       " 'maxloadsofar': 0.9092093829734761,\n",
       " 'meanloadsofar': 0.4203741308657636,\n",
       " 'month': 0.09090909090909091,\n",
       " 'season': 0.0,\n",
       " 'varsofar': 0.021695441627968173,\n",
       " 'week': 0.11538461538461539,\n",
       " 'weekday': 0.5}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_features[str(trainhours[1000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.histogram(a, bins=10, range=None, normed=False, weights=None, density=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_features[str(currtime)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COAST', 'EAST', 'FAR_WEST', 'NORTH', 'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST', 'ERCOT']\n"
     ]
    }
   ],
   "source": [
    "regions= list(vectorized_subregions.keys())\n",
    "print(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hour', 'hourhist_0', 'hourhist_1', 'hourhist_10', 'hourhist_11', 'hourhist_12', 'hourhist_13', 'hourhist_14', 'hourhist_15', 'hourhist_16', 'hourhist_17', 'hourhist_18', 'hourhist_19', 'hourhist_2', 'hourhist_20', 'hourhist_21', 'hourhist_22', 'hourhist_23', 'hourhist_3', 'hourhist_4', 'hourhist_5', 'hourhist_6', 'hourhist_7', 'hourhist_8', 'hourhist_9', 'hourmax_0', 'hourmax_1', 'hourmax_10', 'hourmax_11', 'hourmax_12', 'hourmax_13', 'hourmax_14', 'hourmax_15', 'hourmax_16', 'hourmax_17', 'hourmax_18', 'hourmax_19', 'hourmax_2', 'hourmax_20', 'hourmax_21', 'hourmax_22', 'hourmax_23', 'hourmax_3', 'hourmax_4', 'hourmax_5', 'hourmax_6', 'hourmax_7', 'hourmax_8', 'hourmax_9', 'hourmean_0', 'hourmean_1', 'hourmean_10', 'hourmean_11', 'hourmean_12', 'hourmean_13', 'hourmean_14', 'hourmean_15', 'hourmean_16', 'hourmean_17', 'hourmean_18', 'hourmean_19', 'hourmean_2', 'hourmean_20', 'hourmean_21', 'hourmean_22', 'hourmean_23', 'hourmean_3', 'hourmean_4', 'hourmean_5', 'hourmean_6', 'hourmean_7', 'hourmean_8', 'hourmean_9', 'hourmin_0', 'hourmin_1', 'hourmin_10', 'hourmin_11', 'hourmin_12', 'hourmin_13', 'hourmin_14', 'hourmin_15', 'hourmin_16', 'hourmin_17', 'hourmin_18', 'hourmin_19', 'hourmin_2', 'hourmin_20', 'hourmin_21', 'hourmin_22', 'hourmin_23', 'hourmin_3', 'hourmin_4', 'hourmin_5', 'hourmin_6', 'hourmin_7', 'hourmin_8', 'hourmin_9', 'hourvar_0', 'hourvar_1', 'hourvar_10', 'hourvar_11', 'hourvar_12', 'hourvar_13', 'hourvar_14', 'hourvar_15', 'hourvar_16', 'hourvar_17', 'hourvar_18', 'hourvar_19', 'hourvar_2', 'hourvar_20', 'hourvar_21', 'hourvar_22', 'hourvar_23', 'hourvar_3', 'hourvar_4', 'hourvar_5', 'hourvar_6', 'hourvar_7', 'hourvar_8', 'hourvar_9', 'load', 'maxloadsofar', 'meanloadsofar', 'month', 'season', 'varsofar', 'week', 'weekday']\n"
     ]
    }
   ],
   "source": [
    "#reload feature data\n",
    "regional_load_features = []\n",
    "for region in regions: #['ERCOT']:#regions:\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/\" + region + \"_load_features.json\", 'r') as d:\n",
    "        load_features = json.load(d)\n",
    "        regional_load_features.append(load_features)\n",
    "    \n",
    "features = sorted(load_features[str(allhours[0])].keys())\n",
    "trunc_features = ['load'] #, 'maxloadsofar', 'meanloadsofar', 'varsofar']\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = list(load_features.keys())\n",
    "test_times = times[-8760:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(trainhours[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hourhist'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hourhist_12\"[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERCOT'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n"
     ]
    }
   ],
   "source": [
    "#training data input arrays, output_arrays 24 hours ahead\n",
    "lookback = 24*28\n",
    "training_data_pairs = []\n",
    "midnight_training_data_pairs = []\n",
    "midnight_daymax_training_data_pairs = []\n",
    "ercot_training_data_pairs = []\n",
    "midnight_ercot_training_data_pairs = []\n",
    "midnight_daymax_ercot_training_data_pairs = []\n",
    "\n",
    "#need to do more feature engineering in here\n",
    "\n",
    "for i in range(len(trainhours)-(24 + 1)):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    data_point = []\n",
    "    e_data_point = []\n",
    "    for r in range(len(regional_load_features)):\n",
    "        if regions[r] == 'ERCOT':\n",
    "            for f in range(len(features)):\n",
    "                feat = features[f]\n",
    "                if feat[0:8] == \"hourhist\":\n",
    "                    vals = regional_load_features[r][str(trainhours[i])][feat]\n",
    "                    for val in vals:\n",
    "                        data_point.append(val)\n",
    "                        e_data_point.append(val)\n",
    "                else:\n",
    "                    val = regional_load_features[r][str(trainhours[i])][feat]\n",
    "                    if np.isnan(val):\n",
    "                        try:\n",
    "                            interp = []\n",
    "                            for k in range(3):\n",
    "                                t_f = str(trainhours[i-j+k])\n",
    "                                t_b = str(trainhours[i-j-k])\n",
    "                                v_f = regional_load_features[r][t_f][feat]\n",
    "                                v_b = regional_load_features[r][t_b][feat]\n",
    "                                interp.append(v_f)\n",
    "                                interp.append(v_b)\n",
    "                            val = np.nanmean(interp) \n",
    "                        except:\n",
    "                            pass\n",
    "                    data_point.append(val)\n",
    "                    e_data_point.append(val)  \n",
    "            for j in range(lookback):\n",
    "                for f in range(len(trunc_features)):\n",
    "                    feat = trunc_features[f]\n",
    "                    t = trainhours[i-j]\n",
    "                    val = regional_load_features[r][str(t)][feat]\n",
    "                    if np.isnan(val):\n",
    "                        try:\n",
    "                            interp = []\n",
    "                            for k in range(3):\n",
    "                                t_f = str(trainhours[i-j+k])\n",
    "                                t_b = str(trainhours[i-j-k])\n",
    "                                v_f = regional_load_features[r][t_f][feat]\n",
    "                                v_b = regional_load_features[r][t_b][feat]\n",
    "                                interp.append(v_f)\n",
    "                                interp.append(v_b)\n",
    "                            val = np.nanmean(interp)\n",
    "                        except:\n",
    "                            pass\n",
    "                    data_point.append(val)\n",
    "                    e_data_point.append(val)\n",
    "        else:\n",
    "            for j in range(lookback):\n",
    "                for f in range(len(trunc_features)):\n",
    "                    feat = trunc_features[f]\n",
    "                    t = trainhours[i-j]\n",
    "                    val = regional_load_features[r][str(t)][feat]\n",
    "                    if np.isnan(val):\n",
    "                        try:\n",
    "                            interp = []\n",
    "                            for k in range(3):\n",
    "                                t_f = str(trainhours[i-j+k])\n",
    "                                t_b = str(trainhours[i-j-k])\n",
    "                                v_f = regional_load_features[r][t_f][feat]\n",
    "                                v_b = regional_load_features[r][t_b][feat]\n",
    "                                interp.append(v_f)\n",
    "                                interp.append(v_b)\n",
    "                            val = np.nanmean(interp)\n",
    "                        except:\n",
    "                            pass\n",
    "                    data_point.append(val)\n",
    "        \n",
    "    label = np.zeros((24,))\n",
    "    if trainhours[i].hour == 0:\n",
    "        max_label = np.zeros((24,))\n",
    "    for j in range(24):\n",
    "        label[j,] = vectorized_subregions['ERCOT']['train_labels'][(i + 1) + j]\n",
    "        if trainhours[i].hour == 0:\n",
    "            max_label[j,] = vectorized_subregions['ERCOT']['train_data_norm'][(i + 1) + j]\n",
    "    training_data_pairs.append((np.array(data_point), label)) \n",
    "    ercot_training_data_pairs.append((np.array(e_data_point), label))\n",
    "    \n",
    "    if trainhours[i].hour == 0:\n",
    "        midnight_training_data_pairs.append((np.array(data_point), label))\n",
    "        midnight_daymax_training_data_pairs.append((np.array(data_point), (trainhours[i], np.nanmax(max_label))))\n",
    "        midnight_ercot_training_data_pairs.append((np.array(e_data_point), label))\n",
    "        midnight_daymax_ercot_training_data_pairs.append((np.array(e_data_point), (trainhours[i], np.nanmax(max_label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, '2016-12-30 22:00:00', 'load')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, str(trainhours[i]), feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6321,), (24,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_pairs[0][0].shape, training_data_pairs[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.40434432, 0.40365768, 0.39895331, ..., 0.32825258, 0.33456016,\n",
       "        0.30210486]),\n",
       " array([0.82203196, 0.84828767, 0.84497717, 0.82968037, 0.79531963,\n",
       "        0.73550228, 0.66883562, 0.60570776, 0.57534247, 0.56552511,\n",
       "        0.57180365, 0.61575342, 0.69977169, 0.77842466, 0.8033105 ,\n",
       "        0.79634703, 0.79406393, 0.77853881, 0.76347032, 0.74417808,\n",
       "        0.72614155, 0.70228311, 0.69018265, 0.68847032]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_pairs[1000][0], training_data_pairs[1000][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process daymax data, do CDF ranking for each month index in daymax data pairs second element\n",
    "dmaxdists = {}\n",
    "for pair in midnight_daymax_training_data_pairs:\n",
    "    key = str(pair[1][0].year) #+ str(pair[1][0].month)\n",
    "    if key not in dmaxdists:\n",
    "        dmaxdists[key] = [pair[1][1]]\n",
    "    else:\n",
    "        dmaxdists[key].append(pair[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dmaxdists['2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midnight_daymax_training_data_pairs_copy = []\n",
    "midnight_daymax_ercot_training_data_pairs_copy = []\n",
    "out = []\n",
    "\n",
    "for p in range(len(midnight_daymax_training_data_pairs)):\n",
    "    key = str(midnight_daymax_training_data_pairs[p][1][0].year) #+ \"_\" + str(midnight_daymax_training_data_pairs[p][1][0].month)\n",
    "    val = midnight_daymax_training_data_pairs[p][1][1]\n",
    "    rank = 1.0 - (np.sum( [ 1 for k in dmaxdists[key] if k >= val ] )/float(len(dmaxdists[key])))\n",
    "    midnight_daymax_training_data_pairs_copy.append((midnight_daymax_training_data_pairs[p][0], np.array([rank])))\n",
    "    midnight_daymax_ercot_training_data_pairs_copy.append((midnight_daymax_ercot_training_data_pairs[p][0], np.array([rank])))\n",
    "    out.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(training_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/regional_formatted/load_features/train/\" + str(i) + \"_load_features_training_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(training_data_pairs[i], d)\n",
    "    \n",
    "for i in range(len(midnight_training_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/regional_formatted/midnight_load_features/train/\" + str(i) + \"_midnight_load_features_training_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_training_data_pairs[i], d)\n",
    "    \n",
    "for i in range(len(midnight_daymax_training_data_pairs_copy)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/regional_formatted/midnight_daymax_load_features/train/\" + str(i) + \"_midnight_daymax_load_features_training_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_daymax_training_data_pairs_copy[i], d)\n",
    "    \n",
    "for i in range(len(ercot_training_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/formatted/load_features/train/\" + str(i) + \"_load_features_training_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(ercot_training_data_pairs[i], d)\n",
    "    \n",
    "for i in range(len(midnight_ercot_training_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/formatted/midnight_load_features/train/\" + str(i) + \"_midnight_load_features_training_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_ercot_training_data_pairs[i], d)\n",
    "\n",
    "for i in range(len(midnight_daymax_ercot_training_data_pairs_copy)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/formatted/midnight_daymax_load_features/train/\" + str(i) + \"_midnight_daymax_load_features_training_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_daymax_ercot_training_data_pairs_copy[i], d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([3.91304348e-01,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan,            nan,            nan,            nan,\n",
      "                  nan, 2.45908831e-01, 2.47557965e-01, 2.92304254e-01,\n",
      "       3.02195454e-01, 3.20232342e-01, 3.46523519e-01, 3.65475241e-01,\n",
      "       3.75565362e-01, 3.68342940e-01, 3.56916034e-01, 3.71944877e-01,\n",
      "       3.58441088e-01, 2.49061345e-01, 3.36639812e-01, 3.01395591e-01,\n",
      "       2.43109712e-01, 1.85783249e-01, 2.53702785e-01, 2.67888280e-01,\n",
      "       2.93315408e-01, 3.18581179e-01, 3.29884806e-01, 3.31262061e-01,\n",
      "       3.24271479e-01, 2.45908831e-01, 2.47557965e-01, 2.33138051e-01,\n",
      "       2.41482195e-01, 2.47076947e-01, 2.52944366e-01, 2.54315581e-01,\n",
      "       2.52596583e-01, 2.50664557e-01, 2.66129665e-01, 2.85824228e-01,\n",
      "       2.73282213e-01, 2.49061345e-01, 2.54628238e-01, 2.25121185e-01,\n",
      "       1.81213756e-01, 1.34843409e-01, 2.53702785e-01, 2.67888280e-01,\n",
      "       2.93315408e-01, 3.18581179e-01, 3.29884806e-01, 3.31262061e-01,\n",
      "       3.24271479e-01, 2.45908831e-01, 2.47557965e-01, 1.47388761e-01,\n",
      "       1.57945645e-01, 1.67647705e-01, 1.59387650e-01, 1.49712192e-01,\n",
      "       1.48075660e-01, 1.52295821e-01, 1.61956288e-01, 1.68437843e-01,\n",
      "       1.58646386e-01, 2.49061345e-01, 1.48961710e-01, 1.35005762e-01,\n",
      "       1.12558370e-01, 8.34423657e-02, 2.53702785e-01, 2.67888280e-01,\n",
      "       2.93315408e-01, 3.18581179e-01, 3.29884806e-01, 3.31262061e-01,\n",
      "       3.24271479e-01, 0.00000000e+00, 0.00000000e+00, 1.39553406e-03,\n",
      "       1.60164844e-03, 2.13135655e-03, 2.93695843e-03, 3.62327443e-03,\n",
      "       3.86838762e-03, 3.65267381e-03, 2.72165535e-03, 2.40311826e-03,\n",
      "       2.13639903e-03, 0.00000000e+00, 1.82825017e-03, 1.38482529e-03,\n",
      "       9.08199278e-04, 7.30773348e-04, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 3.24271479e-01, 3.31262061e-01, 2.86143414e-01,\n",
      "       0.00000000e+00, 0.00000000e+00, 1.42298563e-03, 1.01923077e+00,\n",
      "       6.66666667e-01, 3.24271479e-01, 3.31262061e-01, 3.29884806e-01,\n",
      "       3.18581179e-01, 2.93315408e-01, 2.67888280e-01, 2.53702785e-01,\n",
      "       2.49061345e-01, 2.47557965e-01, 2.45908831e-01, 1.30356226e-01,\n",
      "       1.52598136e-01, 1.77021652e-01, 2.02438949e-01, 2.27410877e-01,\n",
      "       2.44597534e-01, 2.09905249e-01, 1.80377515e-01, 1.75239456e-01,\n",
      "       1.75152015e-01, 1.81426022e-01, 1.97875466e-01, 2.12107046e-01,\n",
      "       2.19328569e-01, 2.15781244e-01, 1.98902012e-01, 1.80908188e-01,\n",
      "       1.60638165e-01, 1.40492295e-01, 1.31577230e-01, 1.33193469e-01,\n",
      "       1.43537921e-01, 1.64253617e-01, 1.89382406e-01, 2.23041972e-01,\n",
      "       2.64630425e-01, 2.96365520e-01, 3.18694974e-01, 3.31512155e-01,\n",
      "       3.40009782e-01, 3.16248966e-01, 2.77403542e-01, 2.63921933e-01,\n",
      "       2.61470618e-01, 2.64111103e-01, 2.71940263e-01, 2.85252762e-01,\n",
      "       2.92034323e-01, 2.94667640e-01, 2.87305034e-01, 2.70738235e-01,\n",
      "       2.32289531e-01, 1.80997263e-01, 1.45718073e-01, 1.31490832e-01,\n",
      "       1.30119784e-01, 1.37557222e-01, 1.54555842e-01, 1.87748214e-01,\n",
      "       2.29471986e-01, 2.64885616e-01, 2.84597863e-01, 2.91812328e-01,\n",
      "       2.94921666e-01, 2.52693148e-01, 2.13921133e-01, 2.13013779e-01,\n",
      "       2.21084317e-01, 2.29277295e-01, 2.37853284e-01, 2.43248038e-01,\n",
      "       2.40136323e-01, 2.25964633e-01, 2.07871934e-01, 1.90180964e-01,\n",
      "       1.64404509e-01, 1.20185725e-01, 9.18854536e-02, 8.35265042e-02,\n",
      "       8.94398060e-02, 1.06656391e-01, 1.31199532e-01, 1.74671713e-01,\n",
      "       2.27237494e-01, 2.72543420e-01, 3.04473248e-01, 3.29634495e-01,\n",
      "       3.52317943e-01, 3.33937592e-01, 3.27579012e-01, 3.33857749e-01,\n",
      "       3.29919407e-01, 3.17638164e-01, 2.98605756e-01, 2.78348247e-01,\n",
      "       2.54511764e-01, 2.29563539e-01, 2.05207980e-01, 1.86005857e-01,\n",
      "       1.59192250e-01, 1.18545687e-01, 9.12085962e-02, 8.35943647e-02,\n",
      "       8.86764727e-02, 1.04496985e-01, 1.31749983e-01, 1.73620674e-01,\n",
      "       2.24743733e-01, 2.67981873e-01, 2.99688281e-01, 3.22354779e-01,\n",
      "       3.38436821e-01, 3.11558560e-01, 2.97024112e-01, 3.04308427e-01,\n",
      "       3.06045164e-01, 3.00759041e-01, 2.90268167e-01, 2.79219695e-01,\n",
      "       2.61548185e-01, 2.38005357e-01, 2.10804748e-01, 1.88477726e-01,\n",
      "       1.56135281e-01, 1.12879431e-01, 8.43555278e-02, 7.63809341e-02,\n",
      "       8.22910175e-02, 9.99919306e-02, 1.28564959e-01, 1.73282223e-01,\n",
      "       2.18115583e-01, 2.58406703e-01, 2.82746238e-01, 3.04927204e-01,\n",
      "       3.17281366e-01, 2.90339225e-01, 2.73185346e-01, 2.80013559e-01,\n",
      "       2.79376464e-01, 2.75159491e-01, 2.63941529e-01, 2.48716193e-01,\n",
      "       2.19143751e-01, 1.82135409e-01, 1.42190290e-01, 1.19974695e-01,\n",
      "       1.04972202e-01, 8.48142824e-02, 7.17231885e-02, 6.99579804e-02,\n",
      "       7.76505204e-02, 9.46194770e-02, 1.22087923e-01, 1.57926473e-01,\n",
      "       1.93543754e-01, 2.17435103e-01, 2.30456142e-01, 2.40925060e-01,\n",
      "       2.46734828e-01, 2.20888731e-01, 2.09164012e-01, 2.17287758e-01,\n",
      "       2.24539981e-01, 2.31654029e-01, 2.34338683e-01, 2.24618216e-01,\n",
      "       2.02380473e-01, 1.71867326e-01, 1.29384922e-01, 9.51455792e-02,\n",
      "       7.45254754e-02, 6.04385982e-02, 5.85671419e-02, 6.58830283e-02,\n",
      "       8.20243412e-02, 1.05851943e-01, 1.34420838e-01, 1.71114874e-01,\n",
      "       2.03180554e-01, 2.26704741e-01, 2.44362120e-01, 2.62583548e-01,\n",
      "       2.81658603e-01, 2.64905429e-01, 2.49102449e-01, 2.51402120e-01,\n",
      "       2.51806044e-01, 2.49612654e-01, 2.46700062e-01, 2.38840834e-01,\n",
      "       2.23778590e-01, 1.98777841e-01, 1.60376114e-01, 1.28744748e-01,\n",
      "       1.07348071e-01, 8.83355282e-02, 7.99959810e-02, 8.30023732e-02,\n",
      "       9.50183293e-02, 1.17495021e-01, 1.46985298e-01, 1.90367527e-01,\n",
      "       2.31378778e-01, 2.62050099e-01, 2.82174048e-01, 2.95644527e-01,\n",
      "       3.07875665e-01, 2.87147514e-01, 2.64289320e-01, 2.63047670e-01,\n",
      "       2.66251577e-01, 2.73607741e-01, 2.79749387e-01, 2.85352750e-01,\n",
      "       2.83532186e-01, 2.72603850e-01, 2.52893431e-01, 2.31799503e-01,\n",
      "       2.03586840e-01, 1.67860417e-01, 1.44685425e-01, 1.37733537e-01,\n",
      "       1.44197275e-01, 1.60527949e-01, 1.83215812e-01, 2.21123354e-01,\n",
      "       2.62182760e-01, 2.95547009e-01, 3.10177413e-01, 3.17674846e-01,\n",
      "       3.18365261e-01, 2.82683007e-01, 2.43425947e-01, 2.41063581e-01,\n",
      "       2.47758700e-01, 2.57390892e-01, 2.66227479e-01, 2.82185858e-01,\n",
      "       2.94499194e-01, 2.98950629e-01, 2.95103064e-01, 2.86244336e-01,\n",
      "       2.51230714e-01, 1.92286821e-01, 1.51677957e-01, 1.32642719e-01,\n",
      "       1.31306126e-01, 1.40472231e-01, 1.61624560e-01, 1.97454581e-01,\n",
      "       2.44531570e-01, 2.80735594e-01, 3.00259291e-01, 3.10458993e-01,\n",
      "       3.15334798e-01, 2.76648560e-01, 2.41130246e-01, 2.38517724e-01,\n",
      "       2.44636998e-01, 2.58009869e-01, 2.76038733e-01, 2.98208827e-01,\n",
      "       3.25461170e-01, 3.56940678e-01, 3.87280892e-01, 4.02039126e-01,\n",
      "       3.75380115e-01, 3.12717074e-01, 2.64496371e-01, 2.42274240e-01,\n",
      "       2.36010226e-01, 2.41757796e-01, 2.57456260e-01, 2.92131647e-01,\n",
      "       3.37796238e-01, 3.76535751e-01, 3.94279011e-01, 3.95674445e-01,\n",
      "       3.89362105e-01, 3.34426484e-01, 2.86453324e-01, 2.82632581e-01,\n",
      "       2.97503099e-01, 3.24980192e-01, 3.60320423e-01, 4.08583574e-01,\n",
      "       4.57578675e-01, 5.00316898e-01, 5.35635618e-01, 5.55259289e-01,\n",
      "       5.33542643e-01, 4.69514156e-01, 4.22836407e-01, 4.01247879e-01,\n",
      "       3.94570332e-01, 4.01566426e-01, 4.18843746e-01, 4.56170783e-01,\n",
      "       5.05602476e-01, 5.56940612e-01, 5.80960409e-01, 5.84780168e-01,\n",
      "       5.78763458e-01, 5.22683778e-01, 4.59224426e-01, 4.45099455e-01,\n",
      "       4.57204608e-01, 4.87789780e-01, 5.32275540e-01, 5.85782357e-01,\n",
      "       6.36813506e-01, 6.75412903e-01, 7.05810013e-01, 7.18897336e-01,\n",
      "       6.84848142e-01, 6.14989596e-01, 5.58059459e-01, 5.29294180e-01,\n",
      "       5.19067835e-01, 5.18262428e-01, 5.26400642e-01, 5.54018529e-01,\n",
      "       5.91281500e-01, 6.24088073e-01, 6.37201987e-01, 6.36746501e-01,\n",
      "       6.23266737e-01, 5.62438283e-01, 4.97473766e-01, 4.78712707e-01,\n",
      "       4.82301444e-01, 5.05703535e-01, 5.34372320e-01, 5.63746066e-01,\n",
      "       5.85217739e-01, 5.87494308e-01, 5.56280736e-01, 5.11624577e-01,\n",
      "       4.64724569e-01, 4.20806007e-01, 3.89007378e-01, 3.67502859e-01,\n",
      "       3.50511334e-01, 3.39788085e-01, 3.40445979e-01, 3.56348001e-01,\n",
      "       3.86516146e-01, 4.03848354e-01, 3.99583520e-01, 3.95514430e-01,\n",
      "       3.86003256e-01, 3.37014174e-01, 2.82639490e-01, 2.60398302e-01,\n",
      "       2.55339852e-01, 2.57540200e-01, 2.60583050e-01, 2.56984731e-01,\n",
      "       2.45794041e-01, 2.24471036e-01, 1.92954064e-01, 1.60474958e-01,\n",
      "       1.31939679e-01, 1.04624827e-01, 9.10458614e-02, 8.93629958e-02,\n",
      "       9.74932965e-02, 1.12393010e-01, 1.36978602e-01, 1.77707043e-01,\n",
      "       2.24595476e-01, 2.60509701e-01, 2.80657011e-01, 2.95504217e-01,\n",
      "       3.10627092e-01, 2.88622672e-01, 2.60902848e-01, 2.65103076e-01,\n",
      "       2.76788048e-01, 2.90728853e-01, 3.02101401e-01, 3.14739761e-01,\n",
      "       3.26748679e-01, 3.29045741e-01, 3.33363891e-01, 3.42199054e-01,\n",
      "       3.18422290e-01, 2.42957587e-01, 1.95233137e-01, 1.79951511e-01,\n",
      "       1.81662375e-01, 1.93713167e-01, 2.15994769e-01, 2.57879249e-01,\n",
      "       3.13063597e-01, 3.67738599e-01, 3.95508283e-01, 4.02348451e-01,\n",
      "       4.05614686e-01, 3.73326806e-01, 3.31566867e-01, 3.21646069e-01,\n",
      "       3.28655831e-01, 3.40491373e-01, 3.53588679e-01, 3.69052828e-01,\n",
      "       3.77678016e-01, 3.78346573e-01, 3.75321139e-01, 3.76546302e-01,\n",
      "       3.42446094e-01, 2.53016229e-01, 1.94756968e-01, 1.68800883e-01,\n",
      "       1.64598206e-01, 1.70655421e-01, 1.88823112e-01, 2.25791101e-01,\n",
      "       2.81048384e-01, 3.31543234e-01, 3.58611542e-01, 3.62893695e-01,\n",
      "       3.63382736e-01, 3.24538246e-01, 2.79211605e-01, 2.66096694e-01,\n",
      "       2.67081438e-01, 2.79567374e-01, 2.94901537e-01, 3.12788275e-01,\n",
      "       3.22935969e-01, 3.27651704e-01, 3.29561935e-01, 3.38589127e-01,\n",
      "       3.10776086e-01, 2.26131369e-01, 1.71507589e-01, 1.48508590e-01,\n",
      "       1.42460629e-01, 1.47907796e-01, 1.64282332e-01, 2.02328622e-01,\n",
      "       2.56288031e-01, 3.05585017e-01, 3.34095427e-01, 3.42718604e-01,\n",
      "       3.47149334e-01, 3.08252743e-01, 2.73689124e-01, 2.68588917e-01,\n",
      "       2.72444854e-01, 2.77727679e-01, 2.83310351e-01, 2.90259289e-01,\n",
      "       2.90130573e-01, 2.82901829e-01, 2.75152859e-01, 2.82323849e-01,\n",
      "       2.57753805e-01, 1.77490412e-01, 1.28710266e-01, 1.14628653e-01,\n",
      "       1.13885947e-01, 1.24436780e-01, 1.44627843e-01, 1.85431672e-01,\n",
      "       2.42408534e-01, 2.95037919e-01, 3.22805898e-01, 3.31872166e-01,\n",
      "       3.32651888e-01, 2.93570798e-01, 2.50763733e-01, 2.44679705e-01,\n",
      "       2.48959401e-01, 2.57151099e-01, 2.66138270e-01, 2.80071620e-01,\n",
      "       2.93592898e-01, 3.03279579e-01, 3.08335891e-01, 3.15177503e-01,\n",
      "       2.81041157e-01, 1.88486389e-01, 1.26569002e-01, 1.00041915e-01,\n",
      "       9.21105912e-02, 9.60118378e-02, 1.13875489e-01, 1.53320082e-01,\n",
      "       2.02105442e-01, 2.45094894e-01, 2.66884619e-01, 2.81400943e-01,\n",
      "       2.81079157e-01, 2.39810928e-01, 1.99248552e-01, 1.92045800e-01,\n",
      "       1.95822074e-01, 2.05202780e-01, 2.16194229e-01, 2.27792457e-01,\n",
      "       2.36688245e-01, 2.37211918e-01, 2.22350872e-01, 2.01759615e-01,\n",
      "       1.88552599e-01, 1.72952485e-01, 1.64027674e-01, 1.64719845e-01,\n",
      "       1.74972123e-01, 1.93749660e-01, 2.21034579e-01, 2.58026161e-01,\n",
      "       3.02853216e-01, 3.39331477e-01, 3.60881124e-01, 3.73410507e-01,\n",
      "       3.82587668e-01, 3.63414562e-01, 3.22822551e-01, 3.12999653e-01,\n",
      "       3.19822281e-01, 3.38843570e-01, 3.67034703e-01, 3.96604070e-01,\n",
      "       4.19718692e-01, 4.32472570e-01, 4.25308914e-01, 4.03265581e-01,\n",
      "       3.75760642e-01, 3.42543623e-01, 3.19712578e-01, 3.11736037e-01,\n",
      "       3.16342703e-01, 3.29706935e-01, 3.50133495e-01, 3.84132073e-01,\n",
      "       4.27884240e-01, 4.64285576e-01, 4.82096622e-01, 4.88541942e-01,\n",
      "       4.93436006e-01, 4.59299930e-01, 4.04833104e-01, 3.90439038e-01,\n",
      "       3.98479956e-01, 4.19471117e-01, 4.47935556e-01, 4.83994028e-01,\n",
      "       5.15383478e-01, 5.38248172e-01, 5.48659867e-01, 5.65572954e-01,\n",
      "       5.51438370e-01, 4.68247015e-01, 4.12785761e-01, 3.89397072e-01,\n",
      "       3.83126466e-01, 3.86660382e-01, 3.99777003e-01, 4.31931171e-01,\n",
      "       4.83203993e-01, 5.36444097e-01, 5.65090142e-01, 5.70766692e-01,\n",
      "       5.71470904e-01, 5.38911361e-01, 4.80942542e-01, 4.54746863e-01,\n",
      "       4.49476549e-01, 4.50925623e-01, 4.50700813e-01, 4.50418018e-01,\n",
      "       4.48009858e-01, 4.41916566e-01, 4.32232448e-01, 4.30473954e-01,\n",
      "       3.91754425e-01, 2.95829986e-01, 2.31477840e-01, 1.99996499e-01,\n",
      "       1.89788942e-01, 1.89808290e-01, 2.02124195e-01, 2.32634176e-01,\n",
      "       2.83788863e-01, 3.33405667e-01, 3.60958506e-01, 3.69889717e-01,\n",
      "       3.73341225e-01, 3.45228857e-01, 2.94489992e-01, 2.77832464e-01,\n",
      "       2.78976454e-01, 2.86416654e-01, 2.92469509e-01, 3.04075760e-01,\n",
      "       3.17433002e-01, 3.28362870e-01, 3.39214465e-01, 3.54427023e-01,\n",
      "       3.34714908e-01, 2.42249114e-01, 1.86646210e-01, 1.61238421e-01,\n",
      "       1.56005996e-01, 1.58917404e-01, 1.73204051e-01, 2.04901120e-01,\n",
      "       2.59535926e-01, 3.10455830e-01, 3.41422686e-01, 3.51068781e-01,\n",
      "       3.55194615e-01, 3.21235895e-01, 2.80175009e-01, 2.68839157e-01,\n",
      "       2.70134396e-01, 2.72974708e-01, 2.72736862e-01, 2.76582931e-01,\n",
      "       2.82170996e-01, 2.91654687e-01, 3.01267919e-01, 3.18015830e-01,\n",
      "       2.98384935e-01, 2.10597253e-01, 1.55986033e-01, 1.37142681e-01,\n",
      "       1.36960964e-01, 1.45635211e-01, 1.63191678e-01, 2.00429646e-01,\n",
      "       2.56530300e-01, 3.11114383e-01, 3.48621566e-01, 3.61911706e-01,\n",
      "       3.66870258e-01, 3.33211597e-01, 2.92460110e-01, 2.81009132e-01,\n",
      "       2.79886858e-01, 2.86142786e-01, 2.94260163e-01, 3.06367493e-01,\n",
      "       3.13715125e-01, 3.15278502e-01, 3.12891514e-01, 3.17990809e-01,\n",
      "       2.87285413e-01, 2.03622393e-01, 1.46957130e-01, 1.25251499e-01,\n",
      "       1.22004993e-01, 1.28817364e-01, 1.47768967e-01, 1.84179356e-01,\n",
      "       2.36815614e-01, 2.84446664e-01, 3.12721400e-01, 3.25466721e-01,\n",
      "       3.27975216e-01, 3.04005881e-01, 2.59398154e-01, 2.46463469e-01,\n",
      "       2.45166409e-01, 2.48450698e-01, 2.50874484e-01, 2.49375454e-01,\n",
      "       2.40842193e-01]), array([0.53938356, 0.46906393, 0.37237443, 0.25981735, 0.19189498,\n",
      "       0.15878995, 0.16050228, 0.26518265, 0.48344749, 0.52808219,\n",
      "       0.55205479, 0.55456621, 0.52522831, 0.47614155, 0.43139269,\n",
      "       0.41118721, 0.41381279, 0.43755708, 0.48093607, 0.55022831,\n",
      "       0.618379  , 0.66746575, 0.68356164, 0.6576484 ]))\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/chase/projects/peakload/data/ercot/formatted/load_features/train/9_load_features_training_data_pairs.pck\", 'rb') as d:\n",
    "    data = pickle.load(d)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "#lookback = 24*14\n",
    "test_data_pairs = []\n",
    "midnight_test_data_pairs = []\n",
    "midnight_daymax_test_data_pairs = []\n",
    "ercot_test_data_pairs = []\n",
    "midnight_ercot_test_data_pairs = []\n",
    "midnight_daymax_ercot_test_data_pairs = []\n",
    "\n",
    "\n",
    "for i in range(len(testhours)-(24 + 1)):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    data_point = []\n",
    "    e_data_point = []\n",
    "    for r in range(len(regional_load_features)):\n",
    "        if regions[r] == 'ERCOT': #8: #ercot\n",
    "            for f in range(len(features)):\n",
    "                feat = features[f]\n",
    "                if feat[0:8] == \"hourhist\":\n",
    "                    vals = regional_load_features[r][str(testhours[i])][feat]\n",
    "                    for val in vals:\n",
    "                        data_point.append(val)\n",
    "                        e_data_point.append(val)\n",
    "                else:\n",
    "                    val = regional_load_features[r][str(testhours[i])][feat]\n",
    "                    if np.isnan(val):\n",
    "                        try:\n",
    "                            interp = []\n",
    "                            for k in range(3):\n",
    "                                t_f = str(testhours[i-j+k])\n",
    "                                t_b = str(testhours[i-j-k])\n",
    "                                v_f = regional_load_features[r][t_f][feat]\n",
    "                                v_b = regional_load_features[r][t_b][feat]\n",
    "                                interp.append(v_f)\n",
    "                                interp.append(v_b)\n",
    "                            val = np.nanmean(interp) \n",
    "                        except:\n",
    "                            pass\n",
    "                    data_point.append(val)\n",
    "                    e_data_point.append(val)\n",
    "            for j in range(lookback):\n",
    "                for f in range(len(trunc_features)):\n",
    "                    feat = trunc_features[f]\n",
    "                    t = testhours[i-j]\n",
    "                    val = regional_load_features[r][str(t)][feat]\n",
    "                    if np.isnan(val):\n",
    "                        interp = []\n",
    "                        for k in range(3):\n",
    "                            t_f = str(testhours[i-j+k])\n",
    "                            t_b = str(testhours[i-j-k])\n",
    "                            v_f = regional_load_features[r][t_f][feat]\n",
    "                            v_b = regional_load_features[r][t_b][feat]\n",
    "                            interp.append(v_f)\n",
    "                            interp.append(v_b)\n",
    "                        val = np.nanmean(interp)\n",
    "                    data_point.append(val)\n",
    "                    e_data_point.append(val)\n",
    "        else:\n",
    "            for j in range(lookback):\n",
    "                for f in range(len(trunc_features)):\n",
    "                    feat = trunc_features[f]\n",
    "                    t = testhours[i-j]\n",
    "                    val = regional_load_features[r][str(t)][feat]\n",
    "                    if np.isnan(val):\n",
    "                        interp = []\n",
    "                        for k in range(3):\n",
    "                            t_f = str(testhours[i-j+k])\n",
    "                            t_b = str(testhours[i-j-k])\n",
    "                            v_f = regional_load_features[r][t_f][feat]\n",
    "                            v_b = regional_load_features[r][t_b][feat]\n",
    "                            interp.append(v_f)\n",
    "                            interp.append(v_b)\n",
    "                        val = np.nanmean(interp)\n",
    "                    data_point.append(val)\n",
    "        \n",
    "    label = np.zeros((24,))\n",
    "    if testhours[i].hour == 0:\n",
    "        max_label = np.zeros((24,))\n",
    "        for j in range(24):\n",
    "            label[j,] = vectorized_subregions['ERCOT']['test_labels'][(i + 1) + j]\n",
    "            max_label[j,] = vectorized_subregions['ERCOT']['test_data_norm'][(i + 1) + j]\n",
    "    else:\n",
    "        for j in range(24):\n",
    "            label[j,] = vectorized_subregions['ERCOT']['test_labels'][(i + 1) + j]\n",
    "            \n",
    "    test_data_pairs.append((np.array(data_point), label)) \n",
    "    ercot_test_data_pairs.append((np.array(e_data_point), label))\n",
    "    \n",
    "    if testhours[i].hour == 0:\n",
    "        midnight_test_data_pairs.append((np.array(data_point), label))\n",
    "        midnight_daymax_test_data_pairs.append((np.array(data_point), (testhours[i], np.nanmax(max_label))))\n",
    "        midnight_ercot_test_data_pairs.append((np.array(e_data_point), label))\n",
    "        midnight_daymax_ercot_test_data_pairs.append((np.array(e_data_point), (testhours[i], np.nanmax(max_label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6321,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pairs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process daymax data, do CDF ranking for each month index in daymax data pairs second element\n",
    "dmaxdists = {}\n",
    "for pair in midnight_daymax_test_data_pairs:\n",
    "    key = str(pair[1][0].year) #+ \"_\" + str(pair[1][0].month)\n",
    "    if key not in dmaxdists:\n",
    "        dmaxdists[key] = [pair[1][1]]\n",
    "    else:\n",
    "        dmaxdists[key].append(pair[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3812741044116297"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmax(vectorized_subregions['ERCOT']['test_data_norm'][25:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2017': [0.3312620605468741,\n",
       "  0.3812741044116297,\n",
       "  0.3797906951034232,\n",
       "  0.5101601855970904,\n",
       "  0.6093480797431431,\n",
       "  0.5081321811413946,\n",
       "  0.6715793697404374,\n",
       "  0.74989415307229,\n",
       "  0.6899109703113383,\n",
       "  0.606393131698861,\n",
       "  0.6259308967602643,\n",
       "  0.5023531897081671,\n",
       "  0.43269597954314604,\n",
       "  0.33456016242917497,\n",
       "  0.35278569311793173,\n",
       "  0.31337059125399913,\n",
       "  0.28078737445897,\n",
       "  0.2891384959312401,\n",
       "  0.2693242602843831,\n",
       "  0.2760326771783125,\n",
       "  0.2567575480636889,\n",
       "  0.27589559593370533,\n",
       "  0.23041680652451704,\n",
       "  0.2573718819392626,\n",
       "  0.3894243502798983,\n",
       "  0.38699046978188084,\n",
       "  0.2904079761877366,\n",
       "  0.3179169479323469,\n",
       "  0.4750721381184013,\n",
       "  0.5102744338103243,\n",
       "  0.4715610371766874,\n",
       "  0.5031292202097682,\n",
       "  0.3887280837798041,\n",
       "  0.42496656276724043,\n",
       "  0.40269271351264385,\n",
       "  0.37374124941000436,\n",
       "  0.3216245456291389,\n",
       "  0.32375611894771106,\n",
       "  0.39931709015088973,\n",
       "  0.5149254225414193,\n",
       "  0.5292282623476781,\n",
       "  0.5483163037497515,\n",
       "  0.4915436213876838,\n",
       "  0.45244788109440315,\n",
       "  0.37695159477459694,\n",
       "  0.5293988471582142,\n",
       "  0.5644105363095405,\n",
       "  0.5439771026422136,\n",
       "  0.48420227943861016,\n",
       "  0.3556470270676982,\n",
       "  0.22908129655874857,\n",
       "  0.24778609997765225,\n",
       "  0.4084883152597755,\n",
       "  0.5535914711727433,\n",
       "  0.5672230883338738,\n",
       "  0.5028211378695131,\n",
       "  0.360855905046148,\n",
       "  0.3502795003183053,\n",
       "  0.25560369128538485,\n",
       "  0.40358203343974164,\n",
       "  0.4445184626101245,\n",
       "  0.43489491437596917,\n",
       "  0.35351796601761304,\n",
       "  0.2829578715668952,\n",
       "  0.19344319701577564,\n",
       "  0.2456935779466909,\n",
       "  0.2841904478343774,\n",
       "  0.27737641591521295,\n",
       "  0.27252322754499336,\n",
       "  0.27523730927053974,\n",
       "  0.2587653071710887,\n",
       "  0.1901200419931028,\n",
       "  0.20779185443971213,\n",
       "  0.25154125548428213,\n",
       "  0.2512230608225757,\n",
       "  0.25889237355900596,\n",
       "  0.2485057745426865,\n",
       "  0.21974706511172207,\n",
       "  0.3866598118188369,\n",
       "  0.36880617313464364,\n",
       "  0.4068260624644854,\n",
       "  0.30532472598536525,\n",
       "  0.25273389965250026,\n",
       "  0.25150092217001613,\n",
       "  0.2989003767201011,\n",
       "  0.20509582666351736,\n",
       "  0.20994243985499667,\n",
       "  0.2760346013923152,\n",
       "  0.26538215798994336,\n",
       "  0.3082578933871907,\n",
       "  0.2960727630384729,\n",
       "  0.2586419137916777,\n",
       "  0.257418841512686,\n",
       "  0.2752380403629966,\n",
       "  0.3691989047109157,\n",
       "  0.37362073055806244,\n",
       "  0.29925939191316425,\n",
       "  0.2445961758504614,\n",
       "  0.22784523879696575,\n",
       "  0.21650775823984483,\n",
       "  0.24991005751143058,\n",
       "  0.30217628372402733,\n",
       "  0.3083455028112311,\n",
       "  0.31480683261142306,\n",
       "  0.30474176810061254,\n",
       "  0.29373872364293646,\n",
       "  0.2336906579739469,\n",
       "  0.23145290994417825,\n",
       "  0.252459491686989,\n",
       "  0.2791477037542353,\n",
       "  0.33046507036094713,\n",
       "  0.29225479031754015,\n",
       "  0.4187578596283848,\n",
       "  0.2824618680046512,\n",
       "  0.2801189562204702,\n",
       "  0.3815473538143901,\n",
       "  0.2832072035307201,\n",
       "  0.33884827883013113,\n",
       "  0.4122725464521889,\n",
       "  0.3983569066592655,\n",
       "  0.3522653640070679,\n",
       "  0.3525875688976792,\n",
       "  0.43016684329050175,\n",
       "  0.46364109211376414,\n",
       "  0.5594864101128777,\n",
       "  0.5619569387068785,\n",
       "  0.5699577924593111,\n",
       "  0.29333422006927906,\n",
       "  0.2848068754520213,\n",
       "  0.5035249145355533,\n",
       "  0.5953094750016618,\n",
       "  0.5602487466443934,\n",
       "  0.5124142145329179,\n",
       "  0.41276180409091645,\n",
       "  0.30722645218148537,\n",
       "  0.4705264673648721,\n",
       "  0.6020327134343756,\n",
       "  0.5363553902790777,\n",
       "  0.5850794521465236,\n",
       "  0.5747989843173863,\n",
       "  0.6362410730490472,\n",
       "  0.5636959597322595,\n",
       "  0.5861153609568434,\n",
       "  0.6338919886459111,\n",
       "  0.6023641804232654,\n",
       "  0.6773201188692098,\n",
       "  0.7073786395228665,\n",
       "  0.727727433773228,\n",
       "  0.6508082030775416,\n",
       "  0.6295519648725829,\n",
       "  0.6807309138403671,\n",
       "  0.7657146798141672,\n",
       "  0.7451608404061071,\n",
       "  0.5083207300996467,\n",
       "  0.7144919390058583,\n",
       "  0.7102000695711226,\n",
       "  0.7252725060518976,\n",
       "  0.7224098936188726,\n",
       "  0.637187448114595,\n",
       "  0.6143229659772995,\n",
       "  0.7355644002477931,\n",
       "  0.739673428581886,\n",
       "  0.6989572156021991,\n",
       "  0.711476246122233,\n",
       "  0.8033511769163421,\n",
       "  0.7653285936228599,\n",
       "  0.8078686608004044,\n",
       "  0.7940866098500994,\n",
       "  0.8058694280667964,\n",
       "  0.7722887408054078,\n",
       "  0.7522245591197532,\n",
       "  0.8571750894883635,\n",
       "  0.8505787575210947,\n",
       "  0.8140382353159457,\n",
       "  0.7454593725229444,\n",
       "  0.7104012419666449,\n",
       "  0.7630862279704379,\n",
       "  0.76299650200705,\n",
       "  0.7559476636824642,\n",
       "  0.6527613811914438,\n",
       "  0.5777217101606772,\n",
       "  0.5200755834214884,\n",
       "  0.48962174950664417,\n",
       "  0.5022644464184265,\n",
       "  0.60674190105271,\n",
       "  0.7076394238739355,\n",
       "  0.753243568082208,\n",
       "  0.6963719613328915,\n",
       "  0.5494104593258622,\n",
       "  0.6202297221251514,\n",
       "  0.6364187265524148,\n",
       "  0.7157896610544765,\n",
       "  0.7815952894845573,\n",
       "  0.8130973617158034,\n",
       "  0.8426384608506562,\n",
       "  0.8504515383188448,\n",
       "  0.8509374976099364,\n",
       "  0.8031420548242233,\n",
       "  0.7191197976365681,\n",
       "  0.7583082063215848,\n",
       "  0.7734446343539351,\n",
       "  0.7951125621203614,\n",
       "  0.7665301337027555,\n",
       "  0.7693023418253216,\n",
       "  0.7454935564211022,\n",
       "  0.745154626120219,\n",
       "  0.7251545412634519,\n",
       "  0.6752857481244294,\n",
       "  0.6502487146268054,\n",
       "  0.7661453305200087,\n",
       "  0.8322885497828622,\n",
       "  0.806287423081917,\n",
       "  0.8280865678989564,\n",
       "  0.9022689379492396,\n",
       "  0.9025311286020107,\n",
       "  0.918903103378525,\n",
       "  0.9154700227881416,\n",
       "  0.9061626448260147,\n",
       "  0.8044868157030897,\n",
       "  0.8059433274047001,\n",
       "  0.9141873802205353,\n",
       "  0.9223351417832678,\n",
       "  0.918166600986237,\n",
       "  0.9064399048205565,\n",
       "  0.9103659862003591,\n",
       "  0.865123439467747,\n",
       "  0.8687889783653441,\n",
       "  0.9443642032245693,\n",
       "  0.9286895307727502,\n",
       "  0.8790250279197858,\n",
       "  0.8809256337620763,\n",
       "  0.8753111897885437,\n",
       "  0.8588854906667788,\n",
       "  0.8884784198382962,\n",
       "  0.9635403084379862,\n",
       "  0.8460645885703295,\n",
       "  0.679548803252276,\n",
       "  0.752882389623918,\n",
       "  0.7630754464592459,\n",
       "  0.7474161421899125,\n",
       "  0.7596239064353569,\n",
       "  0.7828930663277557,\n",
       "  0.8152226372011616,\n",
       "  0.7853100527412652,\n",
       "  0.6977836862038245,\n",
       "  0.546502695028229,\n",
       "  0.5432634852795817,\n",
       "  0.6174580651288979,\n",
       "  0.5967108877761284,\n",
       "  0.4609128459147775,\n",
       "  0.6074993193491613,\n",
       "  0.7487189513612879,\n",
       "  0.7764984107508691,\n",
       "  0.7611186033841928,\n",
       "  0.740658729507327,\n",
       "  0.7964446641706808,\n",
       "  0.8016775703085502,\n",
       "  0.7798470128927009,\n",
       "  0.7783386961503164,\n",
       "  0.7006470240513345,\n",
       "  0.5588259702810305,\n",
       "  0.5232327434640933,\n",
       "  0.5904558044946437,\n",
       "  0.586300492949043,\n",
       "  0.6519060048518778,\n",
       "  0.6824266979297369,\n",
       "  0.6478123298436148,\n",
       "  0.4931527387246943,\n",
       "  0.417534076578104,\n",
       "  0.3809451588058688,\n",
       "  0.4577708481320614,\n",
       "  0.5341922026015238,\n",
       "  0.553449082090166,\n",
       "  0.5225903856085864,\n",
       "  0.3931484446457421,\n",
       "  0.28397359848987813,\n",
       "  0.3198725990812193,\n",
       "  0.325770656125349,\n",
       "  0.35824755278048365,\n",
       "  0.4050735220560327,\n",
       "  0.4152532611190449,\n",
       "  0.3923711164070028,\n",
       "  0.40812051540916455,\n",
       "  0.5179096637207947,\n",
       "  0.5035907788151458,\n",
       "  0.4333708078935824,\n",
       "  0.3569122159288706,\n",
       "  0.368853031699906,\n",
       "  0.32898648135343406,\n",
       "  0.3350465491905605,\n",
       "  0.4751863479946414,\n",
       "  0.5060295189967946,\n",
       "  0.5180634921270072,\n",
       "  0.5061680507715267,\n",
       "  0.4401458713253616,\n",
       "  0.33788833725006395,\n",
       "  0.4356231269268894,\n",
       "  0.5243598500069644,\n",
       "  0.4808769833076145,\n",
       "  0.5211531563904953,\n",
       "  0.2941023504391463,\n",
       "  0.2338667520410931,\n",
       "  0.22166045183764452,\n",
       "  0.3108356639806461,\n",
       "  0.4181873562078254,\n",
       "  0.2778725608718054,\n",
       "  0.26736748276217304,\n",
       "  0.25799293518422123,\n",
       "  0.27953394320813835,\n",
       "  0.22769234962576704,\n",
       "  0.22309407370680126,\n",
       "  0.29126858971078873,\n",
       "  0.306432202066052,\n",
       "  0.3229299306366902,\n",
       "  0.33967211806103825,\n",
       "  0.3340689510552526,\n",
       "  0.21198055622657525,\n",
       "  0.23913239327599947,\n",
       "  0.28936412438338904,\n",
       "  0.2785683832519092,\n",
       "  0.2927490096940015,\n",
       "  0.29009846765152725,\n",
       "  0.31563948166653655,\n",
       "  0.23882016983595336,\n",
       "  0.29285018204647423,\n",
       "  0.3792145805002226,\n",
       "  0.37199194931005397,\n",
       "  0.3849467594110031,\n",
       "  0.30975195288743945,\n",
       "  0.27200771111438526,\n",
       "  0.28719480265867753,\n",
       "  0.24942218773166375,\n",
       "  0.3324413352433306,\n",
       "  0.3812946828179006,\n",
       "  0.4376863708928701,\n",
       "  0.3647717789450756,\n",
       "  0.29390801346993595,\n",
       "  0.26767712003469113,\n",
       "  0.3349534325377562,\n",
       "  0.42816169656322906,\n",
       "  0.436895526110046,\n",
       "  0.3887881965070055,\n",
       "  0.4522088147786612,\n",
       "  0.34799127209402475,\n",
       "  0.27063976512709664,\n",
       "  0.39681914206768176,\n",
       "  0.5087096305166379,\n",
       "  0.4304947168478985,\n",
       "  0.31228805445537317,\n",
       "  0.33809299545173044,\n",
       "  0.37432676812485954,\n",
       "  0.35017642881175826,\n",
       "  0.29764036638425423,\n",
       "  0.3141616586944996,\n",
       "  0.33314890831774724,\n",
       "  0.33176890769379436,\n",
       "  0.3088069840595558,\n",
       "  0.3037172532541795,\n",
       "  0.3609614793436621,\n",
       "  0.39778790036663797,\n",
       "  0.4712271977767637,\n",
       "  0.3464684039648597,\n",
       "  0.2834724847514499,\n",
       "  0.26908715530292804]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmaxdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midnight_daymax_test_data_pairs_copy = []\n",
    "midnight_daymax_ercot_test_data_pairs_copy = []\n",
    "\n",
    "for p in range(len(midnight_daymax_test_data_pairs)):\n",
    "    key = str(midnight_daymax_test_data_pairs[p][1][0].year) #+ \"_\" + str(midnight_daymax_test_data_pairs[p][1][0].month)\n",
    "    val = midnight_daymax_test_data_pairs[p][1][1]\n",
    "    rank = 1.0 - (np.sum( [ 1 for k in dmaxdists[key] if k >= val ] )/float(len(dmaxdists[key])))\n",
    "    midnight_daymax_test_data_pairs_copy.append( (midnight_daymax_test_data_pairs[p][0], np.array([rank])) )\n",
    "    midnight_daymax_ercot_test_data_pairs_copy.append( (midnight_daymax_ercot_test_data_pairs[p][0], np.array([rank])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/regional_formatted/load_features/test/\" + str(i) + \"_load_features_test_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(test_data_pairs[i], d)\n",
    "    \n",
    "for i in range(len(midnight_test_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/regional_formatted/midnight_load_features/test/\" + str(i) + \"_midnight_load_features_test_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_test_data_pairs[i], d)\n",
    "    \n",
    "for i in range(len(midnight_daymax_test_data_pairs_copy)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/regional_formatted/midnight_daymax_load_features/test/\" + str(i) + \"_midnight_daymax_load_features_test_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_daymax_test_data_pairs_copy[i], d)\n",
    "    \n",
    "for i in range(len(ercot_test_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/formatted/load_features/test/\" + str(i) + \"_load_features_test_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(ercot_test_data_pairs[i], d)\n",
    "    \n",
    "for i in range(len(midnight_ercot_test_data_pairs)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/formatted/midnight_load_features/test/\" + str(i) + \"_midnight_load_features_test_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_ercot_test_data_pairs[i], d)\n",
    "\n",
    "for i in range(len(midnight_daymax_ercot_test_data_pairs_copy)):\n",
    "    with open(\"/home/chase/projects/peakload/data/ercot/formatted/midnight_daymax_load_features/test/\" + str(i) + \"_midnight_daymax_load_features_test_data_pairs.pck\", 'wb') as d:\n",
    "        pickle.dump(midnight_daymax_ercot_test_data_pairs_copy[i], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/home/chase/projects/peakload/data/ercot/formatted/midnight_daymax_load_features_test_data_pairs.pck\", 'rb') as d:\n",
    "    evaluate = pickle.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "for v in evaluate:\n",
    "    out.append(v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(out[0:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61343"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8735"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "form = \"regional_formatted\"\n",
    "datatype = \"load_features\"\n",
    "outpath = '/home/chase/projects/peakload/data/ercot/weather_pairs/' + form + \"/\" + datatype + \"/\"\n",
    "loadpath = \"/home/chase/projects/peakload/data/ercot/\" + form + \"/\" + datatype + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load temperature data\n",
    "tempdatapath = \"/home/chase/projects/peakload/data/weather/ercot/major_cities/array_formatted/temps_only.pck\"\n",
    "with open(tempdatapath, 'rb') as d:\n",
    "    temp_lists = pickle.load(d)\n",
    "\n",
    "dtpath = \"/home/chase/projects/peakload/data/ercot/\" + form + \"/\" + datatype + \"/\"\n",
    "trainfiles = os.listdir(dtpath + \"train\")\n",
    "trainpaths = {}\n",
    "for i in range(len(trainfiles)):\n",
    "    tokens = trainfiles[i].split(\"_\")\n",
    "    inter = int(tokens[0])\n",
    "    trainpaths[inter] = dtpath + \"train/\" + trainfiles[i]\n",
    "    \n",
    "testfiles = os.listdir(dtpath + \"test\")\n",
    "testpaths = {}\n",
    "for i in range(len(testfiles)):\n",
    "    tokens = testfiles[i].split(\"_\")\n",
    "    inter = int(tokens[0])\n",
    "    testpaths[inter] = dtpath + \"test/\" + testfiles[i]\n",
    "    \n",
    "normed_training_data_pairs = []\n",
    "normed_test_data_pairs = []\n",
    "\n",
    "for i in range(len(trainfiles)):\n",
    "    with open(trainpaths[i], 'rb') as d:\n",
    "        normed_training_data_pairs.append(pickle.load(d))\n",
    "    \n",
    "for i in range(len(testfiles)):\n",
    "    with open(testpaths[i], 'rb') as d:\n",
    "        normed_test_data_pairs.append(pickle.load(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_lists.keys()\n",
    "temps_train = np.zeros((len(temp_lists.keys()), len(temp_lists[0][0:-8760])))\n",
    "temps_test = np.zeros((len(temp_lists.keys()), len(temp_lists[0][-8760:])))\n",
    "\n",
    "for i in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70128\n",
      "70128\n"
     ]
    }
   ],
   "source": [
    "print(len(normed_training_data_pairs) + len(normed_test_data_pairs) + 48 + 2)\n",
    "print(len(temp_lists[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read and sort training and testing pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load normalized weather data\n",
    "weatherdatapath = \"/home/chase/projects/peakload/data/weather/ercot/major_cities/array_formatted/\"\n",
    "\n",
    "with open(weatherdatapath + \"hourly_data_feature_vector.pck\", 'rb') as d:\n",
    "    hourly_weather = pickle.load(d)\n",
    "    \n",
    "with open(weatherdatapath + \"daily_data_feature_vector.pck\", 'rb') as d:\n",
    "    daily_weather = pickle.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70128\n",
      "70128\n"
     ]
    }
   ],
   "source": [
    "allweatherhours = list(hourly_weather.keys())\n",
    "print(len(allhours))\n",
    "\n",
    "train_weatherhours = allweatherhours[0:-8760]\n",
    "test_weatherhours = allweatherhours[-8760:]\n",
    "print(len(allweatherhours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61343"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normed_training_data_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training data pairs\n",
    "weather_array_path = \"/home/chase/projects/peakload/data/weather/ercot/major_cities/array_formatted/yearly_normed_arrays/\"\n",
    "outpath = \"/home/chase/projects/peakload/data/ercot/weather_pairs/\" + form + \"_\" + datatype + \"/\"\n",
    "\n",
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "if not os.path.exists(outpath + \"train\"):\n",
    "    os.mkdir(outpath + \"train\")\n",
    "\n",
    "#write them as you go\n",
    "#weather_normed_training_data_pairs = []\n",
    "hourly_keys = list(hourly_weather.keys())\n",
    "\n",
    "#get the month from trainhours[i]\n",
    "\n",
    "for i in range(len(normed_training_data_pairs)):\n",
    "    pair = normed_training_data_pairs[i]\n",
    "    p1 = np.nan_to_num(pair[0]).flatten()\n",
    "    dtplus = trainhours[i+1]\n",
    "    day = datetime.datetime(year=dtplus.year, month=dtplus.month, day=dtplus.day, hour=0, minute=0, second=0)\n",
    "    day_weather_vec = daily_weather[day] #get the forecast\n",
    "    #hourly_weather_vecs = []\n",
    "    #for j in range(24):\n",
    "    #    hourly_weather_vecs.append(hourly_weather[hourly_keys[i+j+1]])\n",
    "        \n",
    "    wforecast = day_weather_vec.flatten()\n",
    "    #wforecast = np.concatenate((np.asarray(hourly_weather_vecs).flatten(), day_weather_vec.flatten()), axis=0)\n",
    "    wf = np.nan_to_num(wforecast)\n",
    "    \n",
    "    with open(outpath + \"/train/pair_\" + str(i) + \".pck\", 'wb') as d:\n",
    "        pout = (np.concatenate((p1, wf), axis=0), pair[1].flatten())\n",
    "        pickle.dump(pout, d)\n",
    "    #weather_normed_training_data_pairs.append( (np.concatenate((p1, wf), axis=0), pair[1].flatten()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "if not os.path.exists(outpath + \"test\"):\n",
    "    os.mkdir(outpath + \"test\")\n",
    "\n",
    "#test data pairs\n",
    "#weather_normed_test_data_pairs = []\n",
    "\n",
    "for i in range(len(normed_test_data_pairs)):\n",
    "    pair = normed_test_data_pairs[i]\n",
    "    p1 = np.nan_to_num(pair[0]).flatten()\n",
    "    dtplus = testhours[i+1]\n",
    "    day = datetime.datetime(year=dtplus.year, month=dtplus.month, day=dtplus.day, hour=0, minute=0, second=0)\n",
    "    day_weather_vec = daily_weather[day] #get the forecast\n",
    "    #hourly_weather_vecs = []\n",
    "    #for j in range(24):\n",
    "    #    hourly_weather_vecs.append(hourly_weather[test_weatherhours[i+j+1]])\n",
    "        \n",
    "    wforecast = day_weather_vec.flatten()\n",
    "    #wforecast = np.concatenate((np.asarray(hourly_weather_vecs).flatten(), day_weather_vec.flatten()), axis=0)\n",
    "    wf = np.nan_to_num(wforecast)\n",
    "    \n",
    "    with open(outpath + \"/test/pair_\" + str(i) + \".pck\", 'wb') as d:\n",
    "        if pout[0].shape[0] != 1679:\n",
    "            print(pout[0].shape)\n",
    "        pout = (np.concatenate((p1, wf), axis=0), pair[1].flatten())\n",
    "        pickle.dump(pout, d)\n",
    "    #weather_normed_test_data_pairs.append( (np.concatenate((p1, wf), axis=0), pair[1].flatten()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pout[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "#with weather data\n",
    "\n",
    "model_name = \"tanh_deep\"\n",
    "form = \"formatted\"\n",
    "datatype = \"load_features\"\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + model_name + \".py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/\" + form + \"_\" + datatype + \"/train\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/\" + form + \"_\" + datatype + \"/test\"\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 200\n",
    "lookback = 168*4 #two weeks in hours\n",
    "losses = [\"EW\"]\n",
    "hidden_1 = [3000]\n",
    "hidden_2 = [5000]\n",
    "hidden_3 = [3000]\n",
    "hidden_4 = [1000]\n",
    "hidden_5 = [100]\n",
    "hidden_6 = [50]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/train_and_test.sh\", 'w')\n",
    "\n",
    "i = 0\n",
    "for loss in losses:\n",
    "    id_ = str(random.randint(1000,9999))\n",
    "    ident = model_name + \"_\" + id_\n",
    "    h1 = hidden_1[i]\n",
    "    h2 = hidden_2[i]\n",
    "    h3 = hidden_3[i]\n",
    "    h4 = hidden_4[i]\n",
    "    h5 = hidden_5[i]\n",
    "    h6 = hidden_6[i]\n",
    "    params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'HIDDEN_4': h4, 'HIDDEN_5': h5, 'HIDDEN_6': h6, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory', 'BATCH_SIZE': batch_size}\n",
    "    #params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory', 'BATCH_SIZE': batch_size}\n",
    "    parampath = \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + ident + \"_params.pck\"\n",
    "    with open(parampath, 'wb') as p:\n",
    "        pickle.dump(params, p)\n",
    "    shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, ident])\n",
    "    train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "#without weather\n",
    "\n",
    "model_name = \"triple_hidden\" #\"triple_hidden\"\n",
    "form = \"regional_formatted\"\n",
    "datatype = \"load_features\"\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + model_name + \".py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/\" + form + \"/\" + datatype + \"/train\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/\" + form + \"/\" + datatype + \"/test\"\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 200\n",
    "lookback = 168*4 #one week in hours\n",
    "losses = [\"EW\"]\n",
    "hidden_1 = [10000]\n",
    "hidden_2 = [5000]\n",
    "hidden_3 = [100]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/train_and_test.sh\", 'w')\n",
    "\n",
    "i = 0\n",
    "for loss in losses:\n",
    "    id_ = str(random.randint(1000,9999))\n",
    "    ident = model_name + \"_\" + id_\n",
    "    h1 = hidden_1[i]\n",
    "    h2 = hidden_2[i]\n",
    "    h3 = hidden_3[i]\n",
    "    params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory', 'BATCH_SIZE': batch_size}\n",
    "    parampath = \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + ident + \"_params.pck\"\n",
    "    with open(parampath, 'wb') as p:\n",
    "        pickle.dump(params, p)\n",
    "    shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, ident])\n",
    "    train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/home/chase/projects/peakload/data/ercot/formatted/load_features_normed_test_data_pairs.pck\", 'rb') as d:\n",
    "    normed_test_data_pairs = pickle.load(d)\n",
    "    \n",
    "with open(\"/home/chase/projects/peakload/data/ercot/formatted/load_features_normed_training_data_pairs.pck\", 'rb') as d:\n",
    "    normed_training_data_pairs = pickle.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8760"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normed_test_data_pairs) + 168 + 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle training/test data pairs, split out validation\n",
    "\n",
    "random.shuffle(weather_normed_training_data_pairs)\n",
    "training_pairs = weather_normed_training_data_pairs[0:int(0.9*float(len(weather_normed_training_data_pairs)))]\n",
    "val_pairs = weather_normed_training_data_pairs[int(0.9*float(len(weather_normed_training_data_pairs))):]\n",
    "\n",
    "random.shuffle(weather_normed_test_data_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17030,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_normed_training_data_pairs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class linear_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_net, self).__init__()\n",
    "        self.D_in = training_pairs[0][0].shape[0]\n",
    "        self.H1 = 10000 #increased hidden size\n",
    "        #can try additional hidden layer\n",
    "        self.H2 = 5000\n",
    "        self.H3 = 500\n",
    "        self.D_out = 24\n",
    "        self.l1 = nn.Linear(self.D_in, self.H1)\n",
    "        self.l2 = nn.Linear(self.H1, self.H2)\n",
    "        self.l3 = nn.Linear(self.H2, self.H3)\n",
    "        self.l4 = nn.Linear(self.H3, self.D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/single_hidden/single_hidden.py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/formatted/load_features_normed_training_data_pairs.pck\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/formatted/load_features_normed_test_data_pairs.pck\"\n",
    "model_name = \"single_sigmoid\"\n",
    "id_ = str(random.randint(1000,9999))\n",
    "ident = model_name + \"_\" + id_\n",
    "\n",
    "epochs = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"L1\", \"EW\"]\n",
    "hidden_1 = [250, 500, 1000]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/single_hidden/train_and_test.sh\", 'w')\n",
    "\n",
    "for loss in losses:\n",
    "    for h in hidden_1:\n",
    "        params = {'LOOKBACK': lookback, 'HIDDEN_1': h, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'file'}\n",
    "        parampath = \"/home/chase/projects/peakload/src/python/nets/single_hidden/\" + loss + \"loss_h1_\" + str(h) + \"_params.pck\"\n",
    "        with open(parampath, 'wb') as p:\n",
    "            pickle.dump(params, p)\n",
    "        shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, model_name])\n",
    "        train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/tanh_hidden/tanh_hidden.py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/formatted/load_features_normed_training_data_pairs.pck\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/formatted/load_features_normed_test_data_pairs.pck\"\n",
    "model_name = \"tanh_sigmoid\"\n",
    "\n",
    "epochs = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"EW\"]\n",
    "hidden_1 = [250, 500, 1000, 1500]\n",
    "hidden_2 = [250, 500, 1000, 1500]\n",
    "hidden_3 = [250, 500, 1000, 1500]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/tanh_hidden/train_and_test.sh\", 'w')\n",
    "\n",
    "for loss in losses:\n",
    "    for i in range(len(hidden_2)):\n",
    "        for j in range(i, len(hidden_1)):\n",
    "            h1 = hidden_1[j]\n",
    "            h2 = hidden_2[i]\n",
    "            h3 = hidden_3[i]\n",
    "            params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'file'}\n",
    "            parampath = \"/home/chase/projects/peakload/src/python/nets/tanh_hidden/\" + loss + \"loss_h1_\" + str(h1) + \"_h2_\" + str(h2) + \"_h3_\" + str(h3) + \"_params.pck\"\n",
    "            with open(parampath, 'wb') as p:\n",
    "                pickle.dump(params, p)\n",
    "            shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, model_name])\n",
    "            train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/tanh_hidden/tanh_hidden.py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/training\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/test\"\n",
    "model_name = \"tanh_sigmoid_weather\"\n",
    "\n",
    "epochs = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"EW\", \"L1\"]\n",
    "hidden_1 = [250, 500, 1000, 1500, 2500, 5000, 7500, 10000, 20000]\n",
    "hidden_2 = [250, 500, 1000, 1500, 2500, 5000, 7500]\n",
    "hidden_3 = [50, 100, 250, 500, 1000, 1500, 2500, 5000]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/tanh_hidden/train_and_test.sh\", 'w')\n",
    "\n",
    "for loss in losses:\n",
    "    for i in range(len(hidden_2)):\n",
    "        for j in range(i, len(hidden_1)):\n",
    "            h1 = hidden_1[j]\n",
    "            h2 = hidden_2[i]\n",
    "            h3 = hidden_3[i]\n",
    "            params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory'}\n",
    "            parampath = \"/home/chase/projects/peakload/src/python/nets/tanh_hidden/\" + loss + \"loss_h1_\" + str(h1) + \"_h2_\" + str(h2) + \"_h3_\" + str(h3) + \"_params.pck\"\n",
    "            with open(parampath, 'wb') as p:\n",
    "                pickle.dump(params, p)\n",
    "            shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, model_name])\n",
    "            train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/tanh_hidden/tanh_hidden.py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/training\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/test\"\n",
    "model_name = \"tanh_sigmoid_weather\"\n",
    "\n",
    "epochs = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"EW\", \"L1\"]\n",
    "hidden_1 = [250, 500, 1000, 1500, 2500, 5000, 7500, 10000, 20000]\n",
    "hidden_2 = [250, 500, 1000, 1500, 2500, 5000, 7500]\n",
    "hidden_3 = [50, 100, 250, 500, 1000, 1500, 2500, 5000]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/tanh_hidden/train_and_test.sh\", 'w')\n",
    "\n",
    "for loss in losses:\n",
    "    for i in range(len(hidden_2)):\n",
    "        for j in range(i, len(hidden_1)):\n",
    "            h1 = hidden_1[j]\n",
    "            h2 = hidden_2[i]\n",
    "            h3 = hidden_3[i]\n",
    "            params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory'}\n",
    "            parampath = \"/home/chase/projects/peakload/src/python/nets/tanh_hidden/\" + loss + \"loss_h1_\" + str(h1) + \"_h2_\" + str(h2) + \"_h3_\" + str(h3) + \"_params.pck\"\n",
    "            with open(parampath, 'wb') as p:\n",
    "                pickle.dump(params, p)\n",
    "            shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, model_name])\n",
    "            train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "model_name = \"tanh_dropout\"\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + model_name + \".py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/training\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/test\"\n",
    "\n",
    "epochs = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"EW\", \"L1\"]\n",
    "hidden_1 = [1500, 2500, 5000, 7500, 10000, 20000]\n",
    "hidden_2 = [250, 1000, 2500, 5000]\n",
    "hidden_3 = [25, 100, 200, 250]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/train_and_test.sh\", 'w')\n",
    "\n",
    "for loss in losses:\n",
    "    for i in range(len(hidden_2)):\n",
    "        for j in range(i, len(hidden_1)):\n",
    "            h1 = hidden_1[j]\n",
    "            h2 = hidden_2[i]\n",
    "            h3 = hidden_3[i]\n",
    "            params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory'}\n",
    "            parampath = \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + loss + \"loss_h1_\" + str(h1) + \"_h2_\" + str(h2) + \"_h3_\" + str(h3) + \"_params.pck\"\n",
    "            with open(parampath, 'wb') as p:\n",
    "                pickle.dump(params, p)\n",
    "            shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, model_name])\n",
    "            train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-17e3e7da2512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mh4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mh6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'LOOKBACK'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HIDDEN_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HIDDEN_2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HIDDEN_3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HIDDEN_4'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HIDDEN_5'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HIDDEN_6'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOSS'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EPOCHS'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DATA'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'directory'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparampath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/chase/projects/peakload/src/python/nets/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"loss_h1_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_h2_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_h3_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_h4_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_h5_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_h6_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_params.pck\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "model_name = \"tanh_dropout\"\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + model_name + \".py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/training\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/test\"\n",
    "\n",
    "epochs = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"EW\", \"L1\"]\n",
    "hidden_1 = [1500, 2500, 5000, 7500, 10000, 20000]\n",
    "hidden_2 = [1000, 1500, 2500, 5000, 7500]\n",
    "hidden_3 = [50, 500, 1000]\n",
    "hidden_4 = [50, 500, 1000]\n",
    "hidden_5 = [50, 500, 1000]\n",
    "hidden_6 = [50, 100]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/train_and_test.sh\", 'w')\n",
    "\n",
    "for loss in losses:\n",
    "    for i in range(len(hidden_2)):\n",
    "        for j in range(i, len(hidden_1)):\n",
    "            h1 = hidden_1[j]\n",
    "            h2 = hidden_2[i]\n",
    "            h3 = hidden_3[i]\n",
    "            h4 = hidden_4[i]\n",
    "            h5 = hidden_5[i]\n",
    "            h6 = hidden_6[i]\n",
    "            params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'HIDDEN_4': h4, 'HIDDEN_5': h5, 'HIDDEN_6': h6, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory'}\n",
    "            parampath = \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + loss + \"loss_h1_\" + str(h1) + \"_h2_\" + str(h2) + \"_h3_\" + str(h3) + \"_h4_\" + str(h4) + \"_h5_\" + str(h5) + \"_h6_\" + str(h6) + \"_params.pck\"\n",
    "            with open(parampath, 'wb') as p:\n",
    "                pickle.dump(params, p)\n",
    "            shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, model_name])\n",
    "            train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write parameter objects to pck files\n",
    "\n",
    "model_name = \"tanh_dropout\"\n",
    "form = \"formatted\"\n",
    "datatype = \"midnight_daymax_load_features\"\n",
    "\n",
    "call = \"python /home/chase/projects/peakload/src/python/train.py\"\n",
    "net =  \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + model_name + \".py\"\n",
    "#paramfile = \"/home/chase/projects/peakload/src/python/nets/single_hidden/EWloss_h1_250_params.pck\"\n",
    "train_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/\" + form + \"_\" + datatype + \"/training\"\n",
    "test_data_path = \"/home/chase/projects/peakload/data/ercot/weather_pairs/\" + form + \"_\" + datatype + \"/test\"\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "lookback = 168 #one week in hours\n",
    "losses = [\"EW\"]\n",
    "hidden_1 = [15000]\n",
    "hidden_2 = [7500]\n",
    "hidden_3 = [1000]\n",
    "hidden_4 = [1000]\n",
    "hidden_5 = [1000]\n",
    "hidden_6 = [50]\n",
    "\n",
    "train_test_file = open(\"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/train_and_test.sh\", 'w')\n",
    "\n",
    "i = 0\n",
    "for loss in losses:\n",
    "    id_ = str(random.randint(1000,9999))\n",
    "    ident = model_name + \"_\" + id_\n",
    "    h1 = hidden_1[i]\n",
    "    h2 = hidden_2[i]\n",
    "    h3 = hidden_3[i]\n",
    "    #h4 = hidden_4[i]\n",
    "    #h5 = hidden_5[i]\n",
    "    #h6 = hidden_6[i]\n",
    "    #params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'HIDDEN_4': h4, 'HIDDEN_5': h5, 'HIDDEN_6': h6, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory'}\n",
    "    params = {'LOOKBACK': lookback, 'HIDDEN_1': h1, 'HIDDEN_2': h2, 'HIDDEN_3': h3, 'LOSS': loss, 'EPOCHS': epochs, 'DATA': 'directory', 'BATCH_SIZE': batch_size}\n",
    "    parampath = \"/home/chase/projects/peakload/src/python/nets/\" + model_name + \"/\" + ident + \"_params.pck\"\n",
    "    with open(parampath, 'wb') as p:\n",
    "        pickle.dump(params, p)\n",
    "    shcmd = \" \".join([call, net, parampath, train_data_path, test_data_path, ident])\n",
    "    train_test_file.write(shcmd + \";\\n\")\n",
    "        \n",
    "train_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a bash file to train all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class l_linear_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_net, self).__init__()\n",
    "        self.D_in = lookback * 28\n",
    "        self.H1 = 250\n",
    "        self.H2 = 150\n",
    "        self.H3 = 50\n",
    "        self.D_out = 24\n",
    "        self.l1 = nn.Linear(self.D_in, self.H1)\n",
    "        self.l2 = nn.Linear(self.H1, self.H2)\n",
    "        self.l3 = nn.Linear(self.H2, self.H3)\n",
    "        self.l4 = nn.Linear(self.H3, self.D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.l1(F.dropout(x)))\n",
    "        x = F.sigmoid(self.l2(x))\n",
    "        x = F.softmax(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_sample_list(datalist, batchsize):\n",
    "    remainder = len(datalist) % batchsize\n",
    "    diff = batchsize - remainder\n",
    "    tail = datalist[-diff:] + datalist[0:remainder]\n",
    "    out = [ datalist[i*batchsize:(i+1)*batchsize] for i in range(int(float(len(datalist))/float(batchsize)))]\n",
    "    out = out + [tail]\n",
    "    return(out)\n",
    "\n",
    "def torch_reshape_data(databatch):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for sample in databatch:\n",
    "        inputs.append(sample[0].flatten())\n",
    "        labels.append(sample[1].flatten())\n",
    "    return(torch.Tensor(np.asarray(inputs)), torch.Tensor(np.asarray(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.array([1,2,3]) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batched_model_score(net_obj, datalist, thresh=0.85, batchsize=100):\n",
    "    recs = []\n",
    "    precs = []\n",
    "    thresh_losses_low = []\n",
    "    thresh_losses_high = []\n",
    "    set_losses = []\n",
    "    \n",
    "    #batchdata\n",
    "    batches = batch_sample_list(datalist, batchsize)\n",
    "    \n",
    "    #do prediction on datalist\n",
    "    for i, data, in enumerate(batches):\n",
    "        inputs, labels = torch_reshape_data(data)\n",
    "        labels = Variable(labels.cuda())\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        outputs = net_obj(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        set_losses.append(loss.data[0])\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        outputs = outputs.data.cpu().numpy()\n",
    "        \n",
    "        for i in range(outputs.shape[0]):\n",
    "            l = labels[i,:]\n",
    "            o = outputs[i,:]\n",
    "            \n",
    "            if any(l > thresh):\n",
    "                rec = binary_rec(l, o, thresh)\n",
    "                recs.append(rec)\n",
    "            if any(o > thresh):\n",
    "                prec = binary_prec(l, o, thresh)\n",
    "                precs.append(prec)\n",
    "                \n",
    "            loss_low = thresh_loss(l, o, thresh)\n",
    "            loss_high = thresh_loss(l, o, 0.95)\n",
    "            \n",
    "            thresh_losses_low.append(np.mean(loss_low))\n",
    "            thresh_losses_high.append(np.mean(loss_high))\n",
    "    \n",
    "    if len(recs) < 1:\n",
    "        r = np.nan\n",
    "    else:\n",
    "        r = np.mean(recs)\n",
    "    if len(precs) < 1:\n",
    "        p = np.nan\n",
    "    else:\n",
    "        p = np.mean(precs)\n",
    "    if np.isnan(r) or np.isnan(p):\n",
    "        batch_f1 = np.nan\n",
    "    else:\n",
    "        batch_f1 = f1_score(r, p)\n",
    "    \n",
    "    low_thresh_mean_loss = np.nanmean(thresh_losses_low)\n",
    "    high_thresh_mean_loss = np.nanmean(thresh_losses_high)\n",
    "    mean_set_loss = np.mean(set_losses)\n",
    "    \n",
    "    ret = {\"batch_recall\": r, \"batch_precision\": p, \"batch_f1\": batch_f1, \"low_thresh_mean_loss\": low_thresh_mean_loss, \"high_thresh_mean_loss\": high_thresh_mean_loss, \"mean_set_loss\": mean_set_loss}          \n",
    "    return(ret)\n",
    "\n",
    "def print_model_scores(scores, name):\n",
    "    print(\"====\" + name + \"====\")\n",
    "    for k in scores:\n",
    "        print(k + \": \" + str(scores[k]))\n",
    "    print(\"=================\\n\")\n",
    "    \n",
    "    \n",
    "def binary_rec(true, pred, thresh=0.85):\n",
    "    true_pos = 0\n",
    "    pred_pos = 0\n",
    "    for i in range(len(true)):\n",
    "        val = true[i]\n",
    "        if val >= thresh:\n",
    "            true_pos += 1\n",
    "            pred_val = pred[i]\n",
    "            if pred_val >= thresh:\n",
    "                pred_pos += 1\n",
    "    if true_pos == 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return(float(pred_pos)/float(true_pos))\n",
    "    \n",
    "def binary_prec(true, pred, thresh=0.85):\n",
    "    pos = 0\n",
    "    true_pos = 0\n",
    "    for i in range(len(pred)):\n",
    "        val = pred[i]\n",
    "        if val >= thresh:\n",
    "            pos += 1\n",
    "            comp_val = true[i]\n",
    "            if comp_val >= thresh:\n",
    "                true_pos += 1\n",
    "    if pos == 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return(float(true_pos)/float(pos))\n",
    "\n",
    "def thresh_loss(true, pred, thresh=0.85):\n",
    "    out = []\n",
    "    for i in range(len(true)):\n",
    "        val = true[i]\n",
    "        if val >= thresh:\n",
    "            loss = np.abs(val - pred[i])\n",
    "            out.append(loss)\n",
    "    return(out)\n",
    "\n",
    "def f1_score(rec, prec):\n",
    "    return(2.0/((1/rec) + (1/prec)))\n",
    "\n",
    "def set_loss(net_obj, data):\n",
    "    inputs, labels = torch_reshape_data(data)\n",
    "    labels = Variable(labels.cuda())\n",
    "    outputs = net_obj(Variable(inputs.cuda()))\n",
    "    loss = criterion(outputs, labels)\n",
    "    return(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_score(net_obj, datalist, threshes=[0.85, 0.95, 0.99, 0.999], batchsize=100):\n",
    "    #model scoring is on L1 loss\n",
    "    recs = {}\n",
    "    precs = {}\n",
    "    thresh_losses = {}\n",
    "    for t in threshes:\n",
    "        thresh_losses[t] = []\n",
    "        recs[t] = []\n",
    "        precs[t] = []\n",
    "    set_losses = []\n",
    "    \n",
    "    #for also recording weighted loss function later\n",
    "    criterion_l1 = nn.L1Loss()\n",
    "    \n",
    "    #do prediction on datalist\n",
    "    inputs, labels = torch_reshape_data(datalist)\n",
    "    labels = Variable(labels.cuda())\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    outputs = net_obj(inputs)\n",
    "    loss = criterion_l1(outputs, labels)\n",
    "    set_losses.append(loss.data[0])\n",
    "    \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    outputs = outputs.data.cpu().numpy()\n",
    "    \n",
    "    for i in range(outputs.shape[0]):\n",
    "        l = labels[i,:]\n",
    "        o = outputs[i,:]\n",
    "        \n",
    "        for t in threshes:\n",
    "            if any(l > t):\n",
    "                rec = binary_rec(l, o, t)\n",
    "                recs[t].append(rec)\n",
    "            if any(o > t):\n",
    "                prec = binary_prec(l, o, t)\n",
    "                precs[t].append(prec)\n",
    "  \n",
    "            tl = thresh_loss(l, o, t)\n",
    "            thresh_losses[t].append(np.nanmean(tl))\n",
    "    \n",
    "    for t in thresh_losses:\n",
    "        thresh_losses[t] = np.nanmean(thresh_losses[t])\n",
    "        if len(recs[t]) < 1:\n",
    "            recs[t] = np.nan\n",
    "        else:\n",
    "            recs[t] = np.nanmean(recs[t])\n",
    "        if len(precs[t]) < 1:\n",
    "            precs[t] = np.nan\n",
    "        else:\n",
    "            precs[t] = np.nanmean(precs[t])\n",
    "\n",
    "    mean_set_loss = np.nanmean(set_losses)\n",
    "    \n",
    "    ret = {\"batch_recall\": recs, \"batch_precision\": precs, \"thresh_losses\": thresh_losses, \"mean_set_loss\": mean_set_loss}          \n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 4\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "torch.exp(torch.Tensor([0, math.log(2)])) * torch.exp(torch.Tensor([0, math.log(2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expw_mae_loss(input, target, base=10.0):\n",
    "    base = Variable(torch.Tensor([base])).type_as(target)\n",
    "    return(( (input - target).abs() * torch.pow(base, target) ).sum() / input.data.nelement() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net_obj, loss_fnc, opt_fnc, traindata, valdata, batchsize=100, epochs=50):  \n",
    "    train_batches = batch_sample_list(traindata, batchsize)\n",
    "    num_batches = len(train_batches)\n",
    "    tenth = int(num_batches/10)\n",
    "    \n",
    "    training_epoch_loss = []\n",
    "    train_epoch_set_loss = []\n",
    "    val_epoch_set_loss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_batches):\n",
    "            inputs, labels = torch_reshape_data(data)\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) #they need to be .cuda() with each training epoch\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net_obj(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "            #training loss\n",
    "            #print(\"epoch \" + str(epoch) + \" ,iter \" + str(i) + \": \" + str(running_loss))\n",
    "            #training_epoch_loss.append(running_loss)\n",
    "        \n",
    "        print(\"==epoch \" + str(epoch) + \"==\")\n",
    "        train_samp = random.randint(0,num_batches-1)\n",
    "        train_set_loss = set_loss(net_obj, train_batches[train_samp])\n",
    "        train_epoch_set_loss.append(train_set_loss)\n",
    "        print(\"training set sampled loss: \" + str(train_set_loss))\n",
    "        val_set_loss = set_loss(net_obj, valdata)\n",
    "        val_epoch_set_loss.append(val_set_loss)\n",
    "        print(\"validation set loss: \" + str(val_set_loss))\n",
    "       \n",
    "    #sampled epoch set loss\n",
    "    print(\"\\n\")\n",
    "    print(\"Model results\")\n",
    "    \n",
    "    train_model_scores = batched_model_score(net_obj, traindata)\n",
    "    print_model_scores(train_model_scores, \"training data scores\")\n",
    "    \n",
    "    val_model_scores = batched_model_score(net_obj, valdata)\n",
    "    print_model_scores(val_model_scores, \"validation data scores\")\n",
    "                \n",
    "    return(training_epoch_loss, train_epoch_set_loss, val_epoch_set_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#switch nans to -1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100 #batch size\n",
    "\n",
    "net = linear_net().cuda()\n",
    "\n",
    "criterion = expw_mae_loss #nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==epoch 0==\n",
      "training set sampled loss: 0.8030710816383362\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, test_accs = train(net, criterion, optimizer, training_pairs, val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chase/applications/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:39: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====test data scores====\n",
      "batch_recall: {0.85: 0.8184080665931602, 0.95: 0.9420365780671124, 0.99: 0.9969432314410481, 0.999: 1.0}\n",
      "batch_precision: {0.85: 0.8928108353067051, 0.95: 0.6117134316069153, 0.99: 0.15997180162558833, 0.999: 0.007426426426426425}\n",
      "thresh_losses: {0.85: 0.042240818868496385, 0.95: 0.05805267103670435, 0.99: 0.08449693017515857, 0.999: 0.11889468113037005}\n",
      "mean_set_loss: 0.1052764281630516\n",
      "=================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model_scores = model_score(net, weather_normed_test_data_pairs)\n",
    "print_model_scores(test_model_scores, \"test data scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_loss(input, target, size_average=True):\n",
    "    return _functions.thnn.L1Loss.apply(input, target, size_average)ls\n",
    "\n",
    "\n",
    "class L1Loss(_Loss):\n",
    "    r\"\"\"Creates a criterion that measures the mean absolute value of the\n",
    "    element-wise difference between input `x` and target `y`:\n",
    "\n",
    "    :math:`{loss}(x, y)  = 1/n \\sum |x_i - y_i|`\n",
    "\n",
    "    `x` and `y` arbitrary shapes with a total of `n` elements each.\n",
    "\n",
    "    The sum operation still operates over all the elements, and divides by `n`.\n",
    "\n",
    "    The division by `n` can be avoided if one sets the constructor argument\n",
    "    `size_average=False`.\n",
    "\n",
    "    Args:\n",
    "        size_average (bool, optional): By default, the losses are averaged\n",
    "           over observations for each minibatch. However, if the field\n",
    "           size_average is set to False, the losses are instead summed for\n",
    "           each minibatch. Default: True\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, *)` where `*` means, any number of additional\n",
    "          dimensions\n",
    "        - Target: :math:`(N, *)`, same shape as the input\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> loss = nn.L1Loss()\n",
    "        >>> input = autograd.Variable(torch.randn(3, 5), requires_grad=True)\n",
    "        >>> target = autograd.Variable(torch.randn(3, 5))\n",
    "        >>> output = loss(input, target)\n",
    "        >>> output.backward()\n",
    "    \"\"\"\n",
    "    def forward(self, input, target):\n",
    "        _assert_no_grad(target)\n",
    "        return F.l1_loss(input, target, size_average=self.size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22591324,  0.28630137,  0.3872146 ,  0.45502284,  0.48664382,\n",
       "        0.47203195,  0.43481734,  0.38972601,  0.36004567,  0.34406394,\n",
       "        0.33755708,  0.36883563,  0.43584475,  0.45285389,  0.40958905,\n",
       "        0.3303653 ,  0.23504566,  0.16575342,  0.11312786,  0.08070777,\n",
       "        0.0609589 ,  0.0553653 ,  0.05947489,  0.08413242], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27877405,  0.29841518,  0.31782278,  0.3170574 ,  0.30463257,\n",
       "        0.30868047,  0.3124792 ,  0.3071259 ,  0.31804854,  0.31793466,\n",
       "        0.31255594,  0.30287418,  0.30706862,  0.27466702,  0.26765308,\n",
       "        0.23752765,  0.21457636,  0.19224998,  0.19455633,  0.19908968,\n",
       "        0.2263395 ,  0.23829129,  0.25208017,  0.26730546], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs torch.Size([3, 5, 7])\n",
      "hidden torch.Size([2, 5, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.c1 = nn.Conv1d(input_size, hidden_size, 2)\n",
    "        self.p1 = nn.AvgPool1d(2)\n",
    "        self.c2 = nn.Conv1d(hidden_size, hidden_size, 1)\n",
    "        self.p2 = nn.AvgPool1d(2)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        batch_size = inputs.size(1)\n",
    "        \n",
    "        # Turn (seq_len x batch_size x input_size) into (batch_size x input_size x seq_len) for CNN\n",
    "        inputs = inputs.transpose(0, 1).transpose(1, 2)\n",
    "\n",
    "        # Run through Conv1d and Pool1d layers\n",
    "        c = self.c1(inputs)\n",
    "        p = self.p1(c)\n",
    "        c = self.c2(p)\n",
    "        p = self.p2(c)\n",
    "\n",
    "        # Turn (batch_size x hidden_size x seq_len) back into (seq_len x batch_size x hidden_size) for RNN\n",
    "        p = p.transpose(1, 2).transpose(0, 1)\n",
    "        \n",
    "        p = F.tanh(p)\n",
    "        output, hidden = self.gru(p, hidden)\n",
    "        conv_seq_len = output.size(0)\n",
    "        output = output.view(conv_seq_len * batch_size, self.hidden_size) # Treating (conv_seq_len x batch_size) as batch_size for linear layer\n",
    "        output = F.tanh(self.out(output))\n",
    "        output = output.view(conv_seq_len, -1, self.output_size)\n",
    "        return output, hidden\n",
    "\n",
    "input_size = 20\n",
    "hidden_size = 50\n",
    "output_size = 7\n",
    "batch_size = 5\n",
    "n_layers = 2\n",
    "seq_len = 15\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size, n_layers=n_layers)\n",
    "\n",
    "inputs = Variable(torch.rand(seq_len, batch_size, input_size)) # seq_len x batch_size x \n",
    "outputs, hidden = rnn(inputs, None)\n",
    "print('outputs', outputs.size()) # conv_seq_len x batch_size x output_size\n",
    "print('hidden', hidden.size()) # n_layers x batch_size x hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 5, 20])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
